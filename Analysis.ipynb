{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import talib.abstract as ta\n",
    "import tensorflow\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readData(filename):\n",
    "    convertfunc = lambda x: (pd.to_datetime(x,utc=True)).tz_convert('Asia/Kolkata')\n",
    "    return pd.read_csv(filename,\n",
    "                    names=[\"DateTime\",\"open\",\"high\",\"low\",\"close\",\"volume\"],\n",
    "                    dtype=None,\n",
    "                    delimiter = ',',\n",
    "                    converters = {0:convertfunc},\n",
    "                  #  index_col = 0\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A2Z = readData(\"data/A2Z.csv\")\n",
    "Nifty50 = readData(\"data/Nifty50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making sure that 2 timeseries are synced to the smaller time series \n",
    "def sanitizeTimeSeries(ts1,ts2):\n",
    "    # If TS1 is not bigger, then make TS1 the bigger one and TS2 the smaller one.\n",
    "    flipped = 0\n",
    "    if len(ts2) > len(ts1):\n",
    "        flipped = 1\n",
    "        ts1,ts2 = ts2,ts1\n",
    "    for dt in ts1[\"DateTime\"].values:\n",
    "        if dt in ts2['DateTime'].values:\n",
    "            continue\n",
    "        else:\n",
    "            #print(dt)\n",
    "            ts1.drop(ts1[ts1[\"DateTime\"]==dt].index,inplace = True)\n",
    "    if flipped:\n",
    "        return ts2, ts1.reset_index(drop = True)\n",
    "    else:\n",
    "        return ts1.reset_index(drop = True), ts2      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup the time series that will be used for prediction\n",
    "Nifty50Data,A2ZData = sanitizeTimeSeries(Nifty50,A2Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=60):\n",
    "    df = data\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.columns = [str(x) for x in range(1,lag+2)]\n",
    "    return df\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)\n",
    "\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    " \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    "\n",
    "def upOrDown(x):\n",
    "    if x > 0.5:\n",
    "        return 1\n",
    "#     elif x < -0.5:\n",
    "#         return -1\n",
    "    else:\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series = A2ZData['close']\n",
    "rawValues = series.values\n",
    "diffValues = difference(rawValues,1)\n",
    "lag = 60\n",
    "supervised = timeseries_to_supervised(diffValues,lag)\n",
    "supervised = supervised.iloc[lag:]\n",
    "supervised.reset_index(drop=True,inplace=True)\n",
    "supervisedValues = supervised.values\n",
    "# # Make the target column into 0 for stay 1 to buy -1 to sell\n",
    "# supervised['Target'] = supervised.ix[:,lag]-supervised.ix[:,0]\n",
    "# supervised = supervised.drop('61',1)\n",
    "# supervised['Target'] = supervised['Target'].apply(lambda x: upOrDown(x))\n",
    "#Split into train and test\n",
    "trainBegin = int(0.8*len(supervisedValues))\n",
    "train = supervisedValues[0:trainBegin]\n",
    "test = supervisedValues[trainBegin:]\n",
    "X_train,y_train = train[:,0:-1],train[:,-1] # X is the first 60 elements. Y is the 61st element\n",
    "X_test,y_test = test[:,0:-1],test[:,-1]\n",
    "# # scaler, train_scaled, test_scaled = scale(X_train, X_test)\n",
    "# X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for count,row in enumerate(X_train):\n",
    "   # y_train[count] = y_train[count] - np.mean(row)\n",
    "    X_train[count] = row-np.mean(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31125, 60)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model building\n",
    "model = Sequential()\n",
    "layers = [1, 50, 100, 1]\n",
    "model.add(LSTM(\n",
    "    layers[1],\n",
    "    input_shape=(None, layers[0]),\n",
    "    return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(\n",
    "    layers[2],\n",
    "    return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(\n",
    "    layers[3]))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.compile(loss=\"mse\",optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch = 2\n",
    "model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=512, epochs=epoch, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(data,pred_model):\n",
    "    start = 100000 #start with 100000\n",
    "    bought = 0\n",
    "    sold = 0\n",
    "    last = 0\n",
    "    for count,sixtyMin in enumerate(data):\n",
    "        sixtyMin = sixtyMin.reshape(1,sixtyMin.shape[0],sixtyMin.shape[1])\n",
    "        x = pred_model.predict(sixtyMin)[0][0]\n",
    "        last = sixtyMin[0][-1][0]\n",
    "        if x > 0:\n",
    "            start -= last\n",
    "            bought += 1\n",
    "        if count > 6:\n",
    "            break\n",
    "    return start,bought,last\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start,bought,last = evaluate(X_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = X_test[0]\n",
    "temp.shape\n",
    "temp = temp.reshape(1,temp.shape[0],temp.shape[1])\n",
    "temp[0][-1][0]\n",
    "val = model.predict(temp)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:AlgoTrading]",
   "language": "python",
   "name": "conda-env-AlgoTrading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
