{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reads data from Zerodha API historical data files and returns a Pandas DataFrame\n",
    "# Input: Zerodha Api CSV file\n",
    "# Return: Pandas Dataframe of CSV file with correct timezone\n",
    "def readData(filename):\n",
    "    convertfunc = lambda x: (pd.to_datetime(x,utc=True)).tz_convert('Asia/Kolkata')\n",
    "    return pd.read_csv(filename,\n",
    "                    names=[\"datetime\",\"open\",\"high\",\"low\",\"close\",\"volume\"],\n",
    "                    dtype=None,\n",
    "                    delimiter = ',',\n",
    "                    converters = {0:convertfunc},\n",
    "                  #  index_col = 0\n",
    "                   )\n",
    "\n",
    "# Making sure that 2 timeseries are synced to the smaller time series\n",
    "# Goes through 2 timeseries and eliminates any data from any date that is not in both\n",
    "def sycTimeSeries(ts1,ts2):\n",
    "    # If TS1 is not bigger, then make TS1 the bigger one and TS2 the smaller one.\n",
    "    flipped = 0\n",
    "    if len(ts2) > len(ts1):\n",
    "        flipped = 1\n",
    "        ts1,ts2 = ts2,ts1\n",
    "    for dt in ts1[\"DateTime\"].values:\n",
    "        if dt in ts2['DateTime'].values:\n",
    "            continue\n",
    "        else:\n",
    "            #print(dt)\n",
    "            ts1.drop(ts1[ts1[\"DateTime\"]==dt].index,inplace = True)\n",
    "    if flipped:\n",
    "        return ts2, ts1.reset_index(drop = True)\n",
    "    else:\n",
    "        return ts1.reset_index(drop = True), ts2\n",
    "    \n",
    "\n",
    "#Creates Lagged series to generate 60-1 x y split    \n",
    "def timeseriesLagged(data, lag=60):\n",
    "    df = data\n",
    "    columns = [df.shift(i) for i in range(1, lag+2)] \n",
    "    df = pd.concat(columns,axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.columns = [str(lag+2-x) for x in range(1,lag+2)]\n",
    "    df = df[df.columns[::-1]] #Flip because we want newer data on the right\n",
    "    df= df.iloc[lag+1:] # drop the first 'lag' columns because zeroes.\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Binarizes the last column into 1 or 0.\n",
    "# dif is the cost to buy. Rate is the per transasction cost. max is\n",
    "def binarizeTime(series,lag,dif=0,rate=0.01,maxPer=[20]):\n",
    "    #-1 is autocalculate the dif \n",
    "    if dif != 0:\n",
    "        raise Exception(\"dif not yet baked in! \")\n",
    "    series[str(lag+1)] = np.where(series[str(lag)] + dif < series[str(lag+1)], 1, 0)\n",
    "    return series"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:AlgoTrading]",
   "language": "python",
   "name": "conda-env-AlgoTrading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
