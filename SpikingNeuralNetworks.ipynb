{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readData(filename):\n",
    "    convertfunc = lambda x: (pd.to_datetime(x,utc=True)).tz_convert('Asia/Kolkata')\n",
    "    return pd.read_csv(filename,\n",
    "                    names=[\"datetime\",\"open\",\"high\",\"low\",\"close\",\"volume\"],\n",
    "                    dtype=None,\n",
    "                    delimiter = ',',\n",
    "                    converters = {0:convertfunc},\n",
    "                  #  index_col = 0\n",
    "                   )\n",
    "\n",
    "# Making sure that 2 timeseries are synced to the smaller time series \n",
    "def sanitizeTimeSeries(ts1,ts2):\n",
    "    # If TS1 is not bigger, then make TS1 the bigger one and TS2 the smaller one.\n",
    "    flipped = 0\n",
    "    if len(ts2) > len(ts1):\n",
    "        flipped = 1\n",
    "        ts1,ts2 = ts2,ts1\n",
    "    for dt in ts1[\"DateTime\"].values:\n",
    "        if dt in ts2['DateTime'].values:\n",
    "            continue\n",
    "        else:\n",
    "            #print(dt)\n",
    "            ts1.drop(ts1[ts1[\"DateTime\"]==dt].index,inplace = True)\n",
    "    if flipped:\n",
    "        return ts2, ts1.reset_index(drop = True)\n",
    "    else:\n",
    "        return ts1.reset_index(drop = True), ts2\n",
    "    \n",
    "\n",
    "#Creates Lagged series to generate 60-1 x y split    \n",
    "def timeseriesLagged(data, lag=60):\n",
    "    df = data\n",
    "    columns = [df.shift(i) for i in range(1, lag+2)] \n",
    "    df = pd.concat(columns,axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.columns = [str(lag+2-x) for x in range(1,lag+2)]\n",
    "    df = df[df.columns[::-1]] #Flip because we want newer data on the right\n",
    "    df= df.iloc[lag+1:] # drop the first 'lag' columns because zeroes.\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Binarizes the last column into 1 or 0.\n",
    "# dif is the cost to buy. Rate is the per transasction cost. max is\n",
    "def binarizeTime(series,lag,dif=0,rate=0.01,maxPer=[20]):\n",
    "    #-1 is autocalculate the dif \n",
    "    if dif != 0:\n",
    "        raise Exception(\"dif not yet baked in! \")\n",
    "    series[str(lag+1)] = np.where(series[str(lag)] + dif < series[str(lag+1)], 1, 0)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup Parameters\n",
    "dataInit = readData(\"data/TRIL.csv\")\n",
    "data = dataInit['close'].diff().dropna() #difference the data and drop the useless rows\n",
    "#data = (data-data.min())/(data.max()-data.min()) # Min max normalize\n",
    "#data = data/np.linalg.norm(data) #vector norm\n",
    "#data = np.log(data)\n",
    "lag = 4 # 24*5 minutes\n",
    "dif = 0 # difference between prices to trigger purchase for binarize\n",
    "series = timeseriesLagged(data,lag)\n",
    "\n",
    "\n",
    "# Turn the 61st column into or zero\n",
    "#series = binarizeTime(series,lag,dif)\n",
    "seriesVals = series.values\n",
    "\n",
    "#Split into train and test\n",
    "trainBegin = int(0.8*len(seriesVals))\n",
    "train = seriesVals[0:trainBegin]\n",
    "test = seriesVals[trainBegin:]\n",
    "\n",
    "# Split into x and y\n",
    "xTrain,yTrain = train[:,0:-1],train[:,-1] # X is the first 60 elements. Y is the 61st element\n",
    "xTest,yTest = test[:,0:-1],test[:,-1]\n",
    "\n",
    "#Reshape for keras\n",
    "xTrain = xTrain.reshape((xTrain.shape[0], xTrain.shape[1], 1))\n",
    "xTest = xTest.reshape(xTest.shape[0], xTest.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Time : 0.009473562240600586\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, None, 50)          10400     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, None, 100)         60400     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, None, 200)         240800    \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 400)               961600    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 401       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,273,601\n",
      "Trainable params: 1,273,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "import time\n",
    "\n",
    "model = Sequential()\n",
    "layers = [1, 50, 100,200,400,800,1600, 1]\n",
    "model.add(LSTM(\n",
    "        layers[1],\n",
    "        input_shape=(None, 1),\n",
    "        return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=True))\n",
    "\n",
    "\n",
    "model.add(LSTM(\n",
    "        layers[3],\n",
    "        return_sequences=True))\n",
    "\n",
    "model.add(LSTM(\n",
    "        layers[4],\n",
    "        return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(\n",
    "        layers[7]))\n",
    "model.add(Activation(\"linear\"))\n",
    "start = time.time()\n",
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "print (\"Compilation Time : \" + str(time.time() - start))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4976 samples, validate on 1244 samples\n",
      "Epoch 1/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2446 - val_loss: 3.2163\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2398 - val_loss: 3.2157\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2400 - val_loss: 3.2155\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2389 - val_loss: 3.2150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2383 - val_loss: 3.2135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2387 - val_loss: 3.2129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2368 - val_loss: 3.2111\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2376 - val_loss: 3.2095\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2337 - val_loss: 3.2066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2363 - val_loss: 3.2018\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2294 - val_loss: 3.1949\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2276 - val_loss: 3.1862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2211 - val_loss: 3.1771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2191 - val_loss: 3.1695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2122 - val_loss: 3.1636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2070 - val_loss: 3.1637\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2080 - val_loss: 3.1630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2031 - val_loss: 3.1623\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.2014 - val_loss: 3.1698\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/20\n",
      "4976/4976 [==============================] - 0s - loss: 2.1988 - val_loss: 3.1649\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "\n",
    "try:\n",
    "    model.fit(\n",
    "        xTrain, yTrain,\n",
    "        batch_size=1024, epochs=epoch, validation_split=0.20)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print ('Training duration (s) : ', time.time() - global_start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(xTest)\n",
    "#predicted = np.reshape(predicted, (predicted.size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = 0\n",
    "wrong = 0\n",
    "total = 0\n",
    "totalPreds = len(yTest)\n",
    "for i in range(0,totalPreds):\n",
    "    total+= 1\n",
    "    if predicted[i] > 0 and yTest[i] > 0:\n",
    "        corr += 1      \n",
    "    elif predicted[i] < 0 and yTest[i] < 0:\n",
    "        corr += 1\n",
    "    else:\n",
    "        wrong +=1\n",
    "        \n",
    "plt.plot(predicted[:100]*10)\n",
    "plt.plot(yTest[:100])\n",
    "plt.show()\n",
    "\n",
    "print(\"Correct: %d\" % corr)\n",
    "print(\"Wrong:   %d\" % wrong)\n",
    "print(\"Total: %d\" % total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting Tests\n",
    "\n",
    "The rest of this section is devoted to backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import backtrader as bt\n",
    "import backtrader.feeds as btfeeds\n",
    "convertfunc = lambda x: (pd.to_datetime(x,utc=True)).tz_convert('Asia/Kolkata')\n",
    "curData = pd.read_csv(\"data/TRIL.csv\",\n",
    "                    names=[\"datetime\",\"open\",\"high\",\"low\",\"close\",\"volume\"],\n",
    "                    dtype=None,\n",
    "                    delimiter = ',',\n",
    "                    converters = {0:convertfunc},\n",
    "                    index_col = 0\n",
    "                   )\n",
    "curData = curData.iloc[trainBegin:]\n",
    "testData = btfeeds.PandasData(dataname=curData,openinterest=-1,timeframe=bt.TimeFrame.Minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class neuralInput(bt.Indicator):\n",
    "    lines = ('change',)\n",
    "    params = (('period', 20),('neuralModel',None))\n",
    "\n",
    "    def __init__(self):\n",
    "        self.addminperiod(self.params.period)\n",
    "        \n",
    "\n",
    "    def next(self):\n",
    "        datasum = self.data.close.get(size=self.p.period)\n",
    "        datasum = np.array(datasum)\n",
    "        \n",
    "        datasum = datasum.reshape(1, datasum.shape[0],1)\n",
    "        ch = self.params.neuralModel.predict(datasum)\n",
    "        self.lines.change[0] = ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class SmaCross(bt.SignalStrategy):\n",
    "    \n",
    "    def __init__(self):\n",
    "        test = neuralInput(period=lag+1,neuralModel=model)\n",
    "        print(type(test))\n",
    "\n",
    "        \n",
    "cerebro = bt.Cerebro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Portfolio Value: 10000.00\n",
      "<class '__main__.neuralInput'>\n",
      "Final Portfolio Value: 10000.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cerebro.adddata(testData)\n",
    "cerebro.addstrategy(SmaCross)\n",
    "print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "\n",
    "cerebro.run()\n",
    "\n",
    "print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curData"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:AlgoTrading]",
   "language": "python",
   "name": "conda-env-AlgoTrading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
