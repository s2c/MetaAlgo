{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setup\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "import time\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from pythonLib.helper import *\n",
    "import sqlalchemy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "DATA_DIR = 'data' \n",
    "np.random.seed(seed)\n",
    "dbString = 'postgresql://s2c:JANver95@localhost:5432/stockdata'\n",
    "engine = sqlalchemy.create_engine(dbString) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data into postgres\n",
    "\n",
    "We need to load the data into a postgres database. First, we go through each file appending the file name as an added column, then we store each file into the database under the HistoricalData table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Loads everything into postgres, Uncomment if needed\n",
    "# # i = 0\n",
    "# for each_csv in os.listdir(DATA_DIR):\n",
    "#     i = i+1\n",
    "#     File = os.path.join(DATA_DIR,each_csv)\n",
    "#     try:\n",
    "#         dataInit = readData(File)\n",
    "#     except:\n",
    "#         print(each_csv)\n",
    "#     height = np.shape(dataInit)[0]\n",
    "#     width = 1\n",
    "#     tickers = pd.DataFrame(each_csv[:-4], index=range(height), columns=range(width))\n",
    "#     tickers.columns = ['ticker']\n",
    "#     dataInit = tickers.join(dataInit)\n",
    "#     dataInit['datetime'] = dataInit['datetime'].apply(lambda d: str(d))\n",
    "#     engine = sqlalchemy.create_engine('postgresql://s2c:JANver95@localhost:5432/stockdata')\n",
    "#     dataInit.to_sql(\"histdata\",engine,index = False,dtype={'datetime':sqlalchemy.TIMESTAMP(timezone=True)},if_exists='append')\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Database, retrieve a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT ticker,avg(volume) FROM histdata GROUP BY ticker ORDER BY avg DESC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DLF</td>\n",
       "      <td>27371.004363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEDERALBNK</td>\n",
       "      <td>20092.896278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>19765.357590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HINDPETRO</td>\n",
       "      <td>17819.197704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JSWSTEEL</td>\n",
       "      <td>17499.262486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TV18BRDCST</td>\n",
       "      <td>13962.737137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TATAPOWER</td>\n",
       "      <td>11868.993745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HFCL</td>\n",
       "      <td>10676.823751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RASOYPR</td>\n",
       "      <td>9808.606920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JSWENERGY</td>\n",
       "      <td>8716.109570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JETAIRWAYS</td>\n",
       "      <td>7489.075365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BIOCON</td>\n",
       "      <td>6716.137971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ENGINERSIN</td>\n",
       "      <td>5892.256919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TATAGLOBAL</td>\n",
       "      <td>5399.916206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IOB</td>\n",
       "      <td>5313.062931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TVSMOTOR</td>\n",
       "      <td>4879.846055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>JKTYRE</td>\n",
       "      <td>4840.082494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>REIAGROLTD</td>\n",
       "      <td>4663.438280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BALRAMCHIN</td>\n",
       "      <td>3763.878738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DABUR</td>\n",
       "      <td>3708.886975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>INDUSINDBK</td>\n",
       "      <td>3152.410407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>INDOSOLAR</td>\n",
       "      <td>2739.779306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TRIDENT</td>\n",
       "      <td>2660.728354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HINDNATGLS</td>\n",
       "      <td>2108.936009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TAJGVK-BL</td>\n",
       "      <td>1988.299893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SPARC</td>\n",
       "      <td>1899.156814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BFUTILITIE</td>\n",
       "      <td>1845.213332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BEPL</td>\n",
       "      <td>1840.589361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LYCOS-BE</td>\n",
       "      <td>1619.864635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ASTRAMICRO</td>\n",
       "      <td>1337.472871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ALFAICA</td>\n",
       "      <td>5.997923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>TCIDEVELOP</td>\n",
       "      <td>4.300657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>TITANBIO</td>\n",
       "      <td>4.066773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>830PFC2027</td>\n",
       "      <td>3.612517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>SPARCSYS</td>\n",
       "      <td>3.414989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>HDFCMFGETF</td>\n",
       "      <td>3.408039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>CONTPTR</td>\n",
       "      <td>3.397543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>MNPLFIN</td>\n",
       "      <td>3.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>SUMMITSEC</td>\n",
       "      <td>3.206094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>TIDEWATER</td>\n",
       "      <td>2.736097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>PKTEA</td>\n",
       "      <td>2.698015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>RELCNX100</td>\n",
       "      <td>2.626015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>GGDANDE</td>\n",
       "      <td>2.543360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0MFL2020A</td>\n",
       "      <td>1.482456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>GRPLTD</td>\n",
       "      <td>1.394168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>SRTRANSFIN-NW</td>\n",
       "      <td>1.131730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>WENDT</td>\n",
       "      <td>1.038028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>IRFC-N9</td>\n",
       "      <td>0.990990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>722REC22TF</td>\n",
       "      <td>0.957686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>IDBIGOLD</td>\n",
       "      <td>0.914974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0SIFL20</td>\n",
       "      <td>0.898160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>SRIVAJRA</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>TRANSASIA</td>\n",
       "      <td>0.568123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>841IREDA24</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>853MMFSL23</td>\n",
       "      <td>0.183056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0SEFL20B</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ACME</td>\n",
       "      <td>0.109312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>HDFCNIFETF</td>\n",
       "      <td>0.041339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>843IDFBKA</td>\n",
       "      <td>0.035398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>SPECTACLE-BE</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ticker           avg\n",
       "0              DLF  27371.004363\n",
       "1       FEDERALBNK  20092.896278\n",
       "2         RELIANCE  19765.357590\n",
       "3        HINDPETRO  17819.197704\n",
       "4         JSWSTEEL  17499.262486\n",
       "5       TV18BRDCST  13962.737137\n",
       "6        TATAPOWER  11868.993745\n",
       "7             HFCL  10676.823751\n",
       "8          RASOYPR   9808.606920\n",
       "9        JSWENERGY   8716.109570\n",
       "10      JETAIRWAYS   7489.075365\n",
       "11          BIOCON   6716.137971\n",
       "12      ENGINERSIN   5892.256919\n",
       "13      TATAGLOBAL   5399.916206\n",
       "14             IOB   5313.062931\n",
       "15        TVSMOTOR   4879.846055\n",
       "16          JKTYRE   4840.082494\n",
       "17      REIAGROLTD   4663.438280\n",
       "18      BALRAMCHIN   3763.878738\n",
       "19           DABUR   3708.886975\n",
       "20      INDUSINDBK   3152.410407\n",
       "21       INDOSOLAR   2739.779306\n",
       "22         TRIDENT   2660.728354\n",
       "23      HINDNATGLS   2108.936009\n",
       "24       TAJGVK-BL   1988.299893\n",
       "25           SPARC   1899.156814\n",
       "26      BFUTILITIE   1845.213332\n",
       "27            BEPL   1840.589361\n",
       "28        LYCOS-BE   1619.864635\n",
       "29      ASTRAMICRO   1337.472871\n",
       "..             ...           ...\n",
       "181        ALFAICA      5.997923\n",
       "182     TCIDEVELOP      4.300657\n",
       "183       TITANBIO      4.066773\n",
       "184     830PFC2027      3.612517\n",
       "185       SPARCSYS      3.414989\n",
       "186     HDFCMFGETF      3.408039\n",
       "187        CONTPTR      3.397543\n",
       "188        MNPLFIN      3.225806\n",
       "189      SUMMITSEC      3.206094\n",
       "190      TIDEWATER      2.736097\n",
       "191          PKTEA      2.698015\n",
       "192      RELCNX100      2.626015\n",
       "193        GGDANDE      2.543360\n",
       "194      0MFL2020A      1.482456\n",
       "195         GRPLTD      1.394168\n",
       "196  SRTRANSFIN-NW      1.131730\n",
       "197          WENDT      1.038028\n",
       "198        IRFC-N9      0.990990\n",
       "199     722REC22TF      0.957686\n",
       "200       IDBIGOLD      0.914974\n",
       "201        0SIFL20      0.898160\n",
       "202       SRIVAJRA      0.652174\n",
       "203      TRANSASIA      0.568123\n",
       "204     841IREDA24      0.357143\n",
       "205     853MMFSL23      0.183056\n",
       "206       0SEFL20B      0.156250\n",
       "207           ACME      0.109312\n",
       "208     HDFCNIFETF      0.041339\n",
       "209      843IDFBKA      0.035398\n",
       "210   SPECTACLE-BE      0.000000\n",
       "\n",
       "[211 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT ticker,avg(volume) FROM histdata GROUP BY ticker ORDER BY avg DESC\"\n",
    "print(query)\n",
    "stockSet = pd.read_sql(query,engine)\n",
    "\n",
    "stockSet\n",
    "\n",
    "# We use this to select DLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM histdata WHERE ticker = 'DLF' or ticker = 'FEDERALBNK' or ticker = 'RELIANCE'\"\n",
    "res = pd.read_sql(query,engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Helper Functions\n",
    "\n",
    "These functions are more or less general functions that should prove to be fairly useful\n",
    "\n",
    "\n",
    "- **ReadData(filename)** : Reads data from Zerodha API historical data files and returns a Pandas DataFrame\n",
    "- **sycTimeSeries(ts1,ts2)** : Making sure that 2 timeseries are synced to the smaller time series\n",
    "- **timeseriesLagged(data, lag=60)**: Creates Lagged series.Goes through a series and generates an lag+1  dimensional   pandas DataFrame that has each previous lag timeunit.\n",
    "- **binarizeTime(resLagged, rate=0.01)** : Binarizes the last column into 1,-1 or 0 depending whether the price increased, decreased or stayed the same from the beginning to the end of the lag period (triggers on changes by magnitutde = rate*current price).\n",
    "- **findLag(data, targetCorr,suppressed)** :  Finds the right lag given a target correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading some Data and Getting a feel \n",
    "\n",
    "We use an autocorrelation plot to help us figure out what is an optimal amount of lag. We are really looking for a lag that correlates highly. We go through the lags till we reach the last lag that guarantees 0.97 autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup Parameters\n",
    "dataInit = res # Read the stock price data. This is 1 minute data\n",
    "data = dataInit['close'] # extract the 'close' column as a Pandas series\n",
    "# plt.figure()\n",
    "# pd.tools.plotting.lag_plot(data) # Lag plot to check randomness\n",
    "# plt.figure()\n",
    "# pd.tools.plotting.autocorrelation_plot(data) # Auto correlation plot to check if series is autocorrelated at all\n",
    "\n",
    "# # Find the right lag manually\n",
    "# targetCorr = 0.99 # autocorrelation we want\n",
    "# lag = findLag(data,targetCorr,True) # Lag that is indicative \n",
    "# if lag == 99: #if lag is 99 then we can just use any number above it as autocorrelation is guaranteed.\n",
    "#     lag = 120 #nice round 2  hour intervals\n",
    "# print(lag)\n",
    "lag = 5\n",
    "series = timeseriesLagged(data,lag) # Generate the lagged series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create binary series where 0 = hold and 1 = buy\n",
    "buySeries = binarizeTime(series,0)\n",
    "change = buySeries.iloc[:,-1]== -1 # convert to binary\n",
    "buySeries.loc[change,str(lag+1)]=0 # convert to binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create binary series where 0 = hold and 1 = sell\n",
    "sellSeries = binarizeTime(series,0)\n",
    "change = sellSeries.iloc[:,-1]== 1 # find 1s and convert to 0\n",
    "sellSeries.loc[change,str(lag+1)]=0 # \n",
    "change = sellSeries.iloc[:,-1]== -1 # find -1 and conver to 1s\n",
    "sellSeries.loc[change,str(lag+1)]= 1 # convert to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1194340, 6)\n",
      "719012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6020046473654462"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(buySeries.shape) #Total rows \n",
    "print(sum(buySeries.iloc[:,-1]==0)) # Number of holds\n",
    "718929/1194225 # percentage that are holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1194340, 6)\n",
      "726828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6085620381418911"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sellSeries.shape) # Total rows\n",
    "print(sum(sellSeries.iloc[:,-1]==0)) # Number of sells\n",
    "726760/1194225 #  % that are holds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training Data\n",
    "\n",
    "Now that we have an idea of what's going on in the dataset, it is a good time to generate training data. We do an 80:20 training:testing split, and then we randomize the training set because we assume that only the last LAG minutes matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout,Conv1D,MaxPooling1D,Flatten,BatchNormalization,LeakyReLU\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import h5py\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as skp\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get values from pandas series as we need a numpy array for our classifier\n",
    "BuySeriesVals = buySeries.values\n",
    "trainPercent = 0.8 # first 80% of the data is used for training\n",
    "\n",
    "#Split into train and test\n",
    "trainBegin = int(trainPercent*len(BuySeriesVals)) \n",
    "trains = BuySeriesVals[0:trainBegin]\n",
    "train,val = train_test_split(trains)\n",
    "test = BuySeriesVals[trainBegin:]\n",
    "np.random.shuffle(train) # shuffle the training dataset\n",
    "\n",
    "# Split into x and y\n",
    "xTrain,yTrain = train[:,0:-1],train[:,-1] # X is the first lag elements. Y is the lag+1 element\n",
    "xVal,yVal = val[:,0:-1],val[:,-1] # Same for Validation\n",
    "xTest,yTest = test[:,0:-1],test[:,-1] # Same for testing data\n",
    "\n",
    "#scale function to local normalize each row between 0 and 1 so as to amplify any changes\n",
    "# a = lambda row: ((row-np.min(row))/(np.max(row)-np.min(row)))\n",
    "# xTrain = np.apply_along_axis(a,1,xTrain) #scale to 01\n",
    "# xTest = np.apply_along_axis(a,1,xTest) #scale to 0 1\n",
    "# xVal = np.apply_along_axis(a,1,xVal) #scale to 0 1\n",
    "\n",
    "#Reshape for keras\n",
    "xTrain = xTrain.reshape(xTrain.shape[0], xTrain.shape[1],1)\n",
    "xTest = xTest.reshape(xTest.shape[0], xTest.shape[1],1)\n",
    "xVal = xVal.reshape(xVal.shape[0],xVal.shape[1],1)\n",
    "\n",
    "\n",
    "\n",
    "# # # encode class values as integers\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(yTrain)\n",
    "# encodedyTrain = encoder.transform(yTrain)\n",
    "# encodedyTest = encoder.transform(yTest)\n",
    "# encodedyVal = encoder.transform(yVal)\n",
    "# # convert integers to one hot encoded\n",
    "# yTrain = np_utils.to_categorical(encodedyTrain)\n",
    "# yTest = np_utils.to_categorical(encodedyTest)\n",
    "# yVal = np_utils.to_categorical(encodedyVal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  1., ...,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Class weights\n",
    "classWeight = class_weight.compute_class_weight('balanced', np.unique(yTrain), yTrain)\n",
    "classWeight = dict(enumerate(classWeight))\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  1., ...,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert xTrain.shape[0] == yTrain.shape[0]\n",
    "assert xTest.shape[0] == yTest.shape[0]\n",
    "assert xVal.shape[0] == yTest.shape[0]\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet for Buy\n",
    "\n",
    "A CNN to predict buy signals from the above generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learnRate = 0.001\n",
    "batchSize = 10\n",
    "totalBatches = (xTrain.shape[0]//batchSize)\n",
    "epochs = 5\n",
    "\n",
    "nClasses = 2\n",
    "nLength = xTrain.shape[1]\n",
    "inputShape = (nLength,1)\n",
    "# xTrainDataSet = tf.data.Dataset.from_tensors(xTrain)\n",
    "# xTrainIter = xTrainDataSet.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "buyModel = Sequential()\n",
    "buyModel.add(Conv1D(10,kernel_size= 2, strides=1,\n",
    "                 input_shape=inputShape,\n",
    "                 batch_size = None\n",
    "                   ))\n",
    "#buyModel.add(BatchNormalization())\n",
    "buyModel.add(LeakyReLU())\n",
    "buyModel.add(Dropout(0.5))\n",
    "\n",
    "buyModel.add(Conv1D(5, kernel_size= 2, strides=1))\n",
    "#buyModel.add(BatchNormalization())\n",
    "buyModel.add(LeakyReLU())\n",
    "buyModel.add(Dropout(0.5))\n",
    "\n",
    "buyModel.add(Flatten())\n",
    "buyModel.add(Dense(15))\n",
    "buyModel.add(BatchNormalization())\n",
    "buyModel.add(LeakyReLU())\n",
    "\n",
    "buyModel.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 4, 10)             30        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 4, 10)             0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 4, 10)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 3, 5)              105       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)   (None, 3, 5)              0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 3, 5)              0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 15)                60        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 451\n",
      "Trainable params: 421\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "buyModel.summary()\n",
    "buyModel.compile(loss=binary_crossentropy,\n",
    "              optimizer=SGD(lr=learnRate),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "716604/716604 [==============================] - 50s 70us/step - loss: 0.7067 - acc: 0.5278\n",
      "Epoch 2/100\n",
      "716604/716604 [==============================] - 50s 70us/step - loss: 0.6968 - acc: 0.5290\n",
      "Epoch 3/100\n",
      "324192/716604 [============>.................] - ETA: 27s - loss: 0.6946 - acc: 0.5375"
     ]
    }
   ],
   "source": [
    "buyModel.fit(x=xTrain,\n",
    "             y=yTrain, \n",
    "             class_weight=classWeight,\n",
    "             epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = buyModel.evaluate(xTest, yTest, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = buyModel.evaluate(xVal, yVal, verbose=0)\n",
    "print('Val loss:', score[0])\n",
    "print('Val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ConvNet for Buy Didn't work. Trying LSTM for Buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "buyModel = Sequential()\n",
    "buyModel.add(Dense(45,\n",
    "                 input_shape=inputShape,\n",
    "                 batch_size = None\n",
    "                   ))\n",
    "buyModel.add(BatchNormalization())\n",
    "buyModel.add(LeakyReLU())\n",
    "buyModel.add(Dropout(0.5))\n",
    "\n",
    "buyModel.add(Dense(30))\n",
    "buyModel.add(BatchNormalization())\n",
    "buyModel.add(LeakyReLU())\n",
    "buyModel.add(Dropout(0.5))\n",
    "\n",
    "buyModel.add(Flatten())\n",
    "buyModel.add(Dense(15))\n",
    "buyModel.add(BatchNormalization())\n",
    "buyModel.add(LeakyReLU())\n",
    "\n",
    "buyModel.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 60, 45)            90        \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 60, 45)            180       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 60, 45)            0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 60, 45)            0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 60, 30)            1380      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 60, 30)            120       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 60, 30)            0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 60, 30)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 15)                27015     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 15)                60        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 28,861\n",
      "Trainable params: 28,681\n",
      "Non-trainable params: 180\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "buyModel.summary()\n",
    "buyModel.compile(loss=binary_crossentropy,\n",
    "              optimizer=SGD(lr=learnRate),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "179165/179165 [==============================] - 16s 91us/step - loss: 0.6986 - acc: 0.5106\n",
      "Test loss: 0.692930755878\n",
      "Test accuracy: 0.510548876462\n",
      "Val loss: 0.692818339284\n",
      "Val accuracy: 0.509812129536\n"
     ]
    }
   ],
   "source": [
    "buyModel.fit(x=xTrain,\n",
    "             y=yTrain, \n",
    "             class_weight=classWeight,\n",
    "             epochs = 1)\n",
    "yTrain\n",
    "score = buyModel.evaluate(xTest, yTest, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "score = buyModel.evaluate(xVal, yVal, verbose=0)\n",
    "print('Val loss:', score[0])\n",
    "print('Val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:AlgoTrading]",
   "language": "python",
   "name": "conda-env-AlgoTrading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
