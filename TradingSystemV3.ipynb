{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setup\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import time\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from pythonLib.helper import *\n",
    "import sqlalchemy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "DATA_DIR = 'data' \n",
    "np.random.seed(seed)\n",
    "dbString = 'postgresql://s2c:JANver95@localhost:5432/stockdata'\n",
    "engine = sqlalchemy.create_engine(dbString) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data into postgres\n",
    "\n",
    "We need to load the data into a postgres database. First, we go through each file appending the file name as an added column, then we store each file into the database under the HistoricalData table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Loads everything into postgres, Uncomment if not needed\n",
    "# i = 0\n",
    "# for each_csv in os.listdir(DATA_DIR):\n",
    "#     i = i+1\n",
    "#     File = os.path.join(DATA_DIR,each_csv)\n",
    "#     if (File[-10:]==\"Suzlon.csv\"):\n",
    "#         print(File)\n",
    "#         try:\n",
    "#             dataInit = readData(File)\n",
    "#         except:\n",
    "#             print(each_csv)\n",
    "#         height = np.shape(dataInit)[0]\n",
    "#         width = 1\n",
    "#         tickers = pd.DataFrame(each_csv[:-4], index=range(height), columns=range(width))\n",
    "#         tickers.columns = ['ticker']\n",
    "#         dataInit = tickers.join(dataInit)\n",
    "#         dataInit['datetime'] = dataInit['datetime'].apply(lambda d: str(d))\n",
    "#         engine = sqlalchemy.create_engine('postgresql://s2c:JANver95@localhost:5432/stockdata')\n",
    "#         dataInit.to_sql(\"histdata\",engine,index = False,dtype={'datetime':sqlalchemy.TIMESTAMP(timezone=True)},if_exists='append')\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Database, retrieve a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query = \"SELECT ticker,avg(close),avg(volume) FROM histdata GROUP BY ticker ORDER BY avg(volume) DESC\"\n",
    "# stockSet = pd.read_sql(query,engine)\n",
    "# pd.options.display.max_rows = 4000\n",
    "# stockSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM histdata WHERE ticker = 'Suzlon' ORDER BY datetime ASC\"\n",
    "dat = pd.read_sql(query,engine)\n",
    "utc = pytz.UTC\n",
    "startDate = utc.localize(dt.datetime(2016,1,1))\n",
    "endDate = utc.localize(dt.datetime(2018,1,12))\n",
    "backTestStart = endDate\n",
    "backTestEnd = endDate + dt.timedelta(days=7)\n",
    "res = dat[(dat['datetime'] > startDate) & (dat['datetime'] < endDate)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Helper Functions\n",
    "\n",
    "These functions are more or less general functions that should prove to be fairly useful\n",
    "\n",
    "\n",
    "- **ReadData(filename)** : Reads data from Zerodha API historical data files and returns a Pandas DataFrame\n",
    "- **sycTimeSeries(ts1,ts2)** : Making sure that 2 timeseries are synced to the smaller time series\n",
    "- **timeseriesLagged(data, lag=60)**: Creates Lagged series.Goes through a series and generates an lag+1  dimensional   pandas DataFrame that has each previous lag timeunit.\n",
    "- **binarizeTime(resLagged, rate=0.01)** : Binarizes the last column into 1,-1 or 0 depending whether the price increased, decreased or stayed the same from the beginning to the end of the lag period (triggers on changes by magnitutde = rate*current price).\n",
    "- **findLag(data, targetCorr,suppressed)** :  Finds the right lag given a target correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading some Data and Getting a feel \n",
    "\n",
    "We use an autocorrelation plot to help us figure out what is an optimal amount of lag. We are really looking for a lag that correlates highly. We go through the lags till we reach the last lag that guarantees 0.97 autocorrelation\n",
    "\n",
    "## THIS DID NOT WORK AS EXPECTED. REPLACE WITH FALSE NEAREST NEIGHBOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.05</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.10</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.10</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.30</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.10</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.35</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.15</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.30</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.35</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.15</td>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.10</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.20</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.35</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.25</td>\n",
       "      <td>20.35</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20.35</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.15</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.25</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.30</td>\n",
       "      <td>20.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203110</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.40</td>\n",
       "      <td>16.40</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203111</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.40</td>\n",
       "      <td>16.40</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203112</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.40</td>\n",
       "      <td>16.40</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203113</th>\n",
       "      <td>16.40</td>\n",
       "      <td>16.40</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203114</th>\n",
       "      <td>16.40</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203115</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203116</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203117</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203118</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203119</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203120</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203121</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203122</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203123</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203124</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203125</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203126</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203127</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203128</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203129</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203130</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203131</th>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203132</th>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203133</th>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203134</th>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203135</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203136</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203137</th>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203138</th>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203139</th>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203140 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1      2      3      4      5      6      7      8      9     10  \\\n",
       "0       20.05  20.10  20.30  20.10  20.10  20.15  20.15  20.20  20.15  20.10   \n",
       "1       20.10  20.30  20.10  20.10  20.15  20.15  20.20  20.15  20.10  20.15   \n",
       "2       20.30  20.10  20.10  20.15  20.15  20.20  20.15  20.10  20.15  20.20   \n",
       "3       20.10  20.10  20.15  20.15  20.20  20.15  20.10  20.15  20.20  20.20   \n",
       "4       20.10  20.15  20.15  20.20  20.15  20.10  20.15  20.20  20.20  20.35   \n",
       "5       20.15  20.15  20.20  20.15  20.10  20.15  20.20  20.20  20.35  20.30   \n",
       "6       20.15  20.20  20.15  20.10  20.15  20.20  20.20  20.35  20.30  20.25   \n",
       "7       20.20  20.15  20.10  20.15  20.20  20.20  20.35  20.30  20.25  20.35   \n",
       "8       20.15  20.10  20.15  20.20  20.20  20.35  20.30  20.25  20.35  20.25   \n",
       "9       20.10  20.15  20.20  20.20  20.35  20.30  20.25  20.35  20.25  20.25   \n",
       "10      20.15  20.20  20.20  20.35  20.30  20.25  20.35  20.25  20.25  20.30   \n",
       "11      20.20  20.20  20.35  20.30  20.25  20.35  20.25  20.25  20.30  20.20   \n",
       "12      20.20  20.35  20.30  20.25  20.35  20.25  20.25  20.30  20.20  20.20   \n",
       "13      20.35  20.30  20.25  20.35  20.25  20.25  20.30  20.20  20.20  20.20   \n",
       "14      20.30  20.25  20.35  20.25  20.25  20.30  20.20  20.20  20.20  20.20   \n",
       "15      20.25  20.35  20.25  20.25  20.30  20.20  20.20  20.20  20.20  20.25   \n",
       "16      20.35  20.25  20.25  20.30  20.20  20.20  20.20  20.20  20.25  20.20   \n",
       "17      20.25  20.25  20.30  20.20  20.20  20.20  20.20  20.25  20.20  20.25   \n",
       "18      20.25  20.30  20.20  20.20  20.20  20.20  20.25  20.20  20.25  20.25   \n",
       "19      20.30  20.20  20.20  20.20  20.20  20.25  20.20  20.25  20.25  20.20   \n",
       "20      20.20  20.20  20.20  20.20  20.25  20.20  20.25  20.25  20.20  20.25   \n",
       "21      20.20  20.20  20.20  20.25  20.20  20.25  20.25  20.20  20.25  20.25   \n",
       "22      20.20  20.20  20.25  20.20  20.25  20.25  20.20  20.25  20.25  20.20   \n",
       "23      20.20  20.25  20.20  20.25  20.25  20.20  20.25  20.25  20.20  20.20   \n",
       "24      20.25  20.20  20.25  20.25  20.20  20.25  20.25  20.20  20.20  20.20   \n",
       "25      20.20  20.25  20.25  20.20  20.25  20.25  20.20  20.20  20.20  20.25   \n",
       "26      20.25  20.25  20.20  20.25  20.25  20.20  20.20  20.20  20.25  20.25   \n",
       "27      20.25  20.20  20.25  20.25  20.20  20.20  20.20  20.25  20.25  20.25   \n",
       "28      20.20  20.25  20.25  20.20  20.20  20.20  20.25  20.25  20.25  20.25   \n",
       "29      20.25  20.25  20.20  20.20  20.20  20.25  20.25  20.25  20.25  20.25   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "203110  16.45  16.45  16.45  16.40  16.40  16.45  16.45  16.45  16.45  16.45   \n",
       "203111  16.45  16.45  16.40  16.40  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203112  16.45  16.40  16.40  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203113  16.40  16.40  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203114  16.40  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203115  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203116  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203117  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203118  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203119  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203120  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203121  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203122  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.50   \n",
       "203123  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50   \n",
       "203124  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.50   \n",
       "203125  16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.50  16.50   \n",
       "203126  16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.50  16.50  16.45   \n",
       "203127  16.45  16.45  16.45  16.45  16.50  16.50  16.50  16.50  16.45  16.45   \n",
       "203128  16.45  16.45  16.45  16.50  16.50  16.50  16.50  16.45  16.45  16.50   \n",
       "203129  16.45  16.45  16.50  16.50  16.50  16.50  16.45  16.45  16.50  16.50   \n",
       "203130  16.45  16.50  16.50  16.50  16.50  16.45  16.45  16.50  16.50  16.45   \n",
       "203131  16.50  16.50  16.50  16.50  16.45  16.45  16.50  16.50  16.45  16.45   \n",
       "203132  16.50  16.50  16.50  16.45  16.45  16.50  16.50  16.45  16.45  16.45   \n",
       "203133  16.50  16.50  16.45  16.45  16.50  16.50  16.45  16.45  16.45  16.45   \n",
       "203134  16.50  16.45  16.45  16.50  16.50  16.45  16.45  16.45  16.45  16.45   \n",
       "203135  16.45  16.45  16.50  16.50  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203136  16.45  16.50  16.50  16.45  16.45  16.45  16.45  16.45  16.45  16.50   \n",
       "203137  16.50  16.50  16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50   \n",
       "203138  16.50  16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.45   \n",
       "203139  16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.45  16.45   \n",
       "\n",
       "        ...       26     27     28     29     30     31     32     33     34  \\\n",
       "0       ...    20.20  20.25  20.25  20.20  20.25  20.25  20.20  20.20  20.20   \n",
       "1       ...    20.25  20.25  20.20  20.25  20.25  20.20  20.20  20.20  20.25   \n",
       "2       ...    20.25  20.20  20.25  20.25  20.20  20.20  20.20  20.25  20.25   \n",
       "3       ...    20.20  20.25  20.25  20.20  20.20  20.20  20.25  20.25  20.25   \n",
       "4       ...    20.25  20.25  20.20  20.20  20.20  20.25  20.25  20.25  20.25   \n",
       "5       ...    20.25  20.20  20.20  20.20  20.25  20.25  20.25  20.25  20.25   \n",
       "6       ...    20.20  20.20  20.20  20.25  20.25  20.25  20.25  20.25  20.25   \n",
       "7       ...    20.20  20.20  20.25  20.25  20.25  20.25  20.25  20.25  20.25   \n",
       "8       ...    20.20  20.25  20.25  20.25  20.25  20.25  20.25  20.25  20.25   \n",
       "9       ...    20.25  20.25  20.25  20.25  20.25  20.25  20.25  20.25  20.25   \n",
       "10      ...    20.25  20.25  20.25  20.25  20.25  20.25  20.25  20.25  20.25   \n",
       "11      ...    20.25  20.25  20.25  20.25  20.25  20.25  20.25  20.25  20.20   \n",
       "12      ...    20.25  20.25  20.25  20.25  20.25  20.25  20.25  20.20  20.25   \n",
       "13      ...    20.25  20.25  20.25  20.25  20.25  20.25  20.20  20.25  20.20   \n",
       "14      ...    20.25  20.25  20.25  20.25  20.25  20.20  20.25  20.20  20.15   \n",
       "15      ...    20.25  20.25  20.25  20.25  20.20  20.25  20.20  20.15  20.20   \n",
       "16      ...    20.25  20.25  20.25  20.20  20.25  20.20  20.15  20.20  20.20   \n",
       "17      ...    20.25  20.25  20.20  20.25  20.20  20.15  20.20  20.20  20.25   \n",
       "18      ...    20.25  20.20  20.25  20.20  20.15  20.20  20.20  20.25  20.20   \n",
       "19      ...    20.20  20.25  20.20  20.15  20.20  20.20  20.25  20.20  20.20   \n",
       "20      ...    20.25  20.20  20.15  20.20  20.20  20.25  20.20  20.20  20.15   \n",
       "21      ...    20.20  20.15  20.20  20.20  20.25  20.20  20.20  20.15  20.20   \n",
       "22      ...    20.15  20.20  20.20  20.25  20.20  20.20  20.15  20.20  20.25   \n",
       "23      ...    20.20  20.20  20.25  20.20  20.20  20.15  20.20  20.25  20.30   \n",
       "24      ...    20.20  20.25  20.20  20.20  20.15  20.20  20.25  20.30  20.30   \n",
       "25      ...    20.25  20.20  20.20  20.15  20.20  20.25  20.30  20.30  20.25   \n",
       "26      ...    20.20  20.20  20.15  20.20  20.25  20.30  20.30  20.25  20.30   \n",
       "27      ...    20.20  20.15  20.20  20.25  20.30  20.30  20.25  20.30  20.30   \n",
       "28      ...    20.15  20.20  20.25  20.30  20.30  20.25  20.30  20.30  20.30   \n",
       "29      ...    20.20  20.25  20.30  20.30  20.25  20.30  20.30  20.30  20.30   \n",
       "...     ...      ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "203110  ...    16.45  16.45  16.50  16.50  16.45  16.45  16.45  16.45  16.45   \n",
       "203111  ...    16.45  16.50  16.50  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203112  ...    16.50  16.50  16.45  16.45  16.45  16.45  16.45  16.45  16.50   \n",
       "203113  ...    16.50  16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50   \n",
       "203114  ...    16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.45   \n",
       "203115  ...    16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.45  16.45   \n",
       "203116  ...    16.45  16.45  16.45  16.45  16.50  16.50  16.45  16.45  16.50   \n",
       "203117  ...    16.45  16.45  16.45  16.50  16.50  16.45  16.45  16.50  16.50   \n",
       "203118  ...    16.45  16.45  16.50  16.50  16.45  16.45  16.50  16.50  16.45   \n",
       "203119  ...    16.45  16.50  16.50  16.45  16.45  16.50  16.50  16.45  16.45   \n",
       "203120  ...    16.50  16.50  16.45  16.45  16.50  16.50  16.45  16.45  16.45   \n",
       "203121  ...    16.50  16.45  16.45  16.50  16.50  16.45  16.45  16.45  16.45   \n",
       "203122  ...    16.45  16.45  16.50  16.50  16.45  16.45  16.45  16.45  16.45   \n",
       "203123  ...    16.45  16.50  16.50  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203124  ...    16.50  16.50  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203125  ...    16.50  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203126  ...    16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.50   \n",
       "203127  ...    16.45  16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50   \n",
       "203128  ...    16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.45   \n",
       "203129  ...    16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.45  16.45   \n",
       "203130  ...    16.45  16.45  16.45  16.45  16.50  16.50  16.45  16.45  16.45   \n",
       "203131  ...    16.45  16.45  16.45  16.50  16.50  16.45  16.45  16.45  16.45   \n",
       "203132  ...    16.45  16.45  16.50  16.50  16.45  16.45  16.45  16.45  16.45   \n",
       "203133  ...    16.45  16.50  16.50  16.45  16.45  16.45  16.45  16.45  16.45   \n",
       "203134  ...    16.50  16.50  16.45  16.45  16.45  16.45  16.45  16.45  16.50   \n",
       "203135  ...    16.50  16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50   \n",
       "203136  ...    16.45  16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.45   \n",
       "203137  ...    16.45  16.45  16.45  16.45  16.45  16.50  16.50  16.45  16.45   \n",
       "203138  ...    16.45  16.45  16.45  16.45  16.50  16.50  16.45  16.45  16.45   \n",
       "203139  ...    16.45  16.45  16.45  16.50  16.50  16.45  16.45  16.45  16.45   \n",
       "\n",
       "           35  \n",
       "0       20.25  \n",
       "1       20.25  \n",
       "2       20.25  \n",
       "3       20.25  \n",
       "4       20.25  \n",
       "5       20.25  \n",
       "6       20.25  \n",
       "7       20.25  \n",
       "8       20.25  \n",
       "9       20.25  \n",
       "10      20.20  \n",
       "11      20.25  \n",
       "12      20.20  \n",
       "13      20.15  \n",
       "14      20.20  \n",
       "15      20.20  \n",
       "16      20.25  \n",
       "17      20.20  \n",
       "18      20.20  \n",
       "19      20.15  \n",
       "20      20.20  \n",
       "21      20.25  \n",
       "22      20.30  \n",
       "23      20.30  \n",
       "24      20.25  \n",
       "25      20.30  \n",
       "26      20.30  \n",
       "27      20.30  \n",
       "28      20.30  \n",
       "29      20.35  \n",
       "...       ...  \n",
       "203110  16.45  \n",
       "203111  16.50  \n",
       "203112  16.50  \n",
       "203113  16.45  \n",
       "203114  16.45  \n",
       "203115  16.50  \n",
       "203116  16.50  \n",
       "203117  16.45  \n",
       "203118  16.45  \n",
       "203119  16.45  \n",
       "203120  16.45  \n",
       "203121  16.45  \n",
       "203122  16.45  \n",
       "203123  16.45  \n",
       "203124  16.45  \n",
       "203125  16.50  \n",
       "203126  16.50  \n",
       "203127  16.45  \n",
       "203128  16.45  \n",
       "203129  16.45  \n",
       "203130  16.45  \n",
       "203131  16.45  \n",
       "203132  16.45  \n",
       "203133  16.50  \n",
       "203134  16.50  \n",
       "203135  16.45  \n",
       "203136  16.45  \n",
       "203137  16.45  \n",
       "203138  16.45  \n",
       "203139  16.50  \n",
       "\n",
       "[203140 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Setup Parameters\n",
    "dataInit = res # Read the stock price data. This is 1 minute data\n",
    "data = dataInit['close'] # extract the 'close' column as a Pandas series\n",
    "# plt.figure()\n",
    "# pd.tools.plotting.lag_plot(data) # Lag plot to check randomness\n",
    "# plt.figure()\n",
    "# pd.tools.plotting.autocorrelation_plot(data) # Auto correlation plot to check if series is autocorrelated at all\n",
    "\n",
    "# # Find the right lag manually\n",
    "# targetCorr = 0.99 # autocorrelation we want\n",
    "# lag = findLag(data,targetCorr,True) # Lag that is indicative \n",
    "# if lag == 99: #if lag is 99 then we can just use any number above it as autocorrelation is guaranteed.\n",
    "#     lag = 120 #nice round 2  hour intervals\n",
    "# print(lag)\n",
    "lag = 30 \n",
    "lookahead = 5\n",
    "flat = 0.05\n",
    "series = timeseriesLagged(data,lag + lookahead-1) # Generate the lagged series\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create binary series where 0 = hold and 1 = buy\n",
    "\n",
    "\n",
    "buySeries = binarizeTime(series,0,lookahead = lookahead, flat= flat)\n",
    "change = buySeries.iloc[:,-1]== -1 # convert to binary\n",
    "buySeries.loc[change,str(lag+1)]=0 # convert to binary\n",
    "# buySeries['31'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary series where 0 = hold and 1 = sell\n",
    "sellSeries = binarizeTime(series,0,lookahead=lookahead,flat=flat)\n",
    "change = sellSeries.iloc[:,-1]== 1 # find 1s and convert to 0\n",
    "sellSeries.loc[change,str(lag+1)]=0 # \n",
    "change = sellSeries.iloc[:,-1]== -1 # find -1 and conver to 1s\n",
    "sellSeries.loc[change,str(lag+1)]= 1 # convert to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training Data\n",
    "\n",
    "Now that we have an idea of what's going on in the dataset, it is a good time to generate training data. We do an 90:20 training:testing split, and then we randomize the training set because we assume that only the last LAG minutes matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Activation,Dense,LSTM, Dropout,Conv1D,MaxPooling1D,Permute,Merge,Input\n",
    "from keras.layers import Flatten,BatchNormalization,LeakyReLU,GlobalAveragePooling1D,concatenate\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "import h5py\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as skp\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/sklearn/preprocessing/data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# Get values from pandas series as we need a numpy array for our classifier\n",
    "BuySeriesVals = buySeries.values\n",
    "np.random.shuffle(BuySeriesVals) #shuffle the entire dataset\n",
    "trainPercent = 0.9 # first 80% of the data is used for training\n",
    "np.random.shuffle(BuySeriesVals)\n",
    "#Split into train and test\n",
    "trainBegin = int(trainPercent*len(BuySeriesVals)) \n",
    "trains = BuySeriesVals[0:trainBegin]\n",
    "train,val = train_test_split(trains)\n",
    "test = BuySeriesVals[trainBegin:]\n",
    "# np.random.shuffle(train) # shuffle the training dataset\n",
    "\n",
    "# Split into x and y\n",
    "xTrain,yTrain = train[:,0:-1],train[:,-1] # X is the first lag elements. Y is the lag+1 element\n",
    "xVal,yVal = val[:,0:-1],val[:,-1] # Same for Validation\n",
    "xTest,yTest = test[:,0:-1],test[:,-1] # Same for testing data\n",
    "\n",
    "#scale function to local normalize each row between 0 and 1 so as to amplify any changes\n",
    "# standardize = lambda row: skp.normalize(row)\n",
    "xTrain =skp.scale(xTrain,axis=1) #np.apply_along_axis(standardize,1,xTrain) #scale to 01\n",
    "xTest = skp.scale(xTest,axis=1) #scale to 0 1\n",
    "xVal = skp.scale(xVal,axis=1) #scale to 0 1\n",
    "\n",
    "#Reshape for keras\n",
    "xTrain = xTrain.reshape(xTrain.shape[0], xTrain.shape[1],1)\n",
    "xTest = xTest.reshape(xTest.shape[0], xTest.shape[1],1)\n",
    "xVal = xVal.reshape(xVal.shape[0],xVal.shape[1],1)\n",
    "\n",
    "\n",
    "# # # encode class values as integers\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(yTrain)\n",
    "# encodedyTrain = encoder.transform(yTrain)\n",
    "# encodedyTest = encoder.transform(yTest)\n",
    "# encodedyVal = encoder.transform(yVal)\n",
    "# # convert integers to one hot encoded\n",
    "# yTrain = np_utils.to_categorical(encodedyTrain)\n",
    "# yTest = np_utils.to_categorical(encodedyTest)\n",
    "# yVal = np_utils.to_categorical(encodedyVal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.77098983401556387, 1: 1.4225438323477539}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Class weights\n",
    "classWeight = class_weight.compute_class_weight('balanced', np.unique(yTrain), yTrain)\n",
    "classWeight = dict(enumerate(classWeight))\n",
    "classWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137119, 30, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert xTrain.shape[0] == yTrain.shape[0]\n",
    "assert xTest.shape[0] == yTest.shape[0]\n",
    "assert xVal.shape[0] == yVal.shape[0]\n",
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet for Buy\n",
    "\n",
    "A CNN to predict buy signals from the above generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learnRate = 0.5\n",
    "batchSize = 10\n",
    "totalBatches = (xTrain.shape[0]//batchSize)\n",
    "epochs = 5\n",
    "\n",
    "nClasses = 2\n",
    "nLength = xTrain.shape[1]\n",
    "inputShape = (nLength,1)\n",
    "# xTrainDataSet = tf.data.Dataset.from_tensors(xTrain)\n",
    "# xTrainIter = xTrainDataSet.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "#https://arxiv.org/pdf/1709.05206.pdf LSTM-FCN\n",
    "buyModelConv = Sequential()\n",
    "buyModelConv.add(Conv1D(12,kernel_size= 1, strides=1,\n",
    "                 input_shape=inputShape,\n",
    "                 batch_size = None\n",
    "                   ))\n",
    "buyModelConv.add(BatchNormalization())\n",
    "buyModelConv.add(Activation('relu'))\n",
    "\n",
    "\n",
    "buyModelConv.add(Conv1D(6, kernel_size= 1, strides=1))\n",
    "buyModelConv.add(BatchNormalization())\n",
    "buyModelConv.add(Activation('relu'))\n",
    "\n",
    "buyModelConv.add(Conv1D(6,kernel_size= 1, strides=1))\n",
    "buyModelConv.add(BatchNormalization())\n",
    "buyModelConv.add(Activation('relu'))\n",
    "\n",
    "buyModelConv.add(GlobalAveragePooling1D())\n",
    "im = buyModelConv.layers[0].input\n",
    "buyConvInput = buyModelConv(im)\n",
    " ########################################\n",
    "buyModelLSTM = Sequential()\n",
    "buyModelLSTM.add(Permute((2, 1), input_shape=inputShape))\n",
    "buyModelLSTM.add(LSTM(5))\n",
    "buyModelLSTM.add(Dropout(0.5))\n",
    "im2 = buyModelLSTM.layers[0].input\n",
    "buyLstmInput = buyModelLSTM(im2)\n",
    "#############################\n",
    "\n",
    "merged = concatenate([buyConvInput, buyLstmInput])\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "buyModel = Model(inputs=[im,im2],outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_1_input (InputLayer)     (None, 30, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1_input (InputLayer)    (None, 30, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 6)            240         conv1d_1_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 5)            720         permute_1_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 11)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            12          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 972\n",
      "Trainable params: 924\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "buyModel.summary()\n",
    "buyModel.compile(loss=binary_crossentropy,\n",
    "              optimizer=SGD(lr=learnRate),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 137119 samples, validate on 45707 samples\n",
      "Epoch 1/3\n",
      "137119/137119 [==============================] - 23s 170us/step - loss: 0.6027 - acc: 0.6937 - val_loss: 0.5546 - val_acc: 0.7209\n",
      "Epoch 2/3\n",
      "137119/137119 [==============================] - 22s 158us/step - loss: 0.5944 - acc: 0.7058 - val_loss: 0.5972 - val_acc: 0.7100\n",
      "Epoch 3/3\n",
      "137119/137119 [==============================] - 21s 157us/step - loss: 0.5939 - acc: 0.7051 - val_loss: 0.5842 - val_acc: 0.7189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec33335d68>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buyModel.fit(x=[xTrain,xTrain],\n",
    "             y=yTrain, \n",
    "             class_weight=classWeight,\n",
    "             validation_data = ([xVal,xVal],yVal),\n",
    "             epochs = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.582439846266\n",
      "Test accuracy: 0.719109973394\n"
     ]
    }
   ],
   "source": [
    "score = buyModel.evaluate([xTest,xTest], yTest, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ConvNet for Sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/sklearn/preprocessing/data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# Get values from pandas series as we need a numpy array for our classifier\n",
    "sellSeriesVals = sellSeries.values\n",
    "trainPercent = 0.9 # first 80% of the data is used for training\n",
    "\n",
    "#Split into train and test\n",
    "trainBegin = int(trainPercent*len(sellSeriesVals)) \n",
    "trains = sellSeriesVals[0:trainBegin]\n",
    "train,val = train_test_split(trains)\n",
    "test = sellSeriesVals[trainBegin:]\n",
    "np.random.shuffle(train) # shuffle the training dataset\n",
    "\n",
    "# Split into x and y\n",
    "xTrain,yTrain = train[:,0:-1],train[:,-1] # X is the first lag elements. Y is the lag+1 element\n",
    "xVal,yVal = val[:,0:-1],val[:,-1] # Same for Validation\n",
    "xTest,yTest = test[:,0:-1],test[:,-1] # Same for testing data\n",
    "\n",
    "#scale function to local normalize each row between 0 and 1 so as to amplify any changes\n",
    "# standardize = lambda row: skp.normalize(row)\n",
    "xTrain =skp.scale(xTrain,axis=1) #np.apply_along_axis(standardize,1,xTrain) #scale to 01\n",
    "xTest = skp.scale(xTest,axis=1) #scale to 0 1\n",
    "xVal = skp.scale(xVal,axis=1) #scale to 0 1\n",
    "\n",
    "#Reshape for keras\n",
    "xTrain = xTrain.reshape(xTrain.shape[0], xTrain.shape[1],1)\n",
    "xTest = xTest.reshape(xTest.shape[0], xTest.shape[1],1)\n",
    "xVal = xVal.reshape(xVal.shape[0],xVal.shape[1],1)\n",
    "\n",
    "\n",
    "\n",
    "# # # encode class values as integers\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(yTrain)\n",
    "# encodedyTrain = encoder.transform(yTrain)\n",
    "# encodedyTest = encoder.transform(yTest)\n",
    "# encodedyVal = encoder.transform(yVal)\n",
    "# # convert integers to one hot encoded\n",
    "# yTrain = np_utils.to_categorical(encodedyTrain)\n",
    "# yTest = np_utils.to_categorical(encodedyTest)\n",
    "# yVal = np_utils.to_categorical(encodedyVal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute Class weights\n",
    "classWeight = class_weight.compute_class_weight('balanced', np.unique(yTrain), yTrain)\n",
    "classWeight = dict(enumerate(classWeight))\n",
    "xTest.shape\n",
    "assert xTrain.shape[0] == yTrain.shape[0]\n",
    "assert xTest.shape[0] == yTest.shape[0]\n",
    "assert xVal.shape[0] == yVal.shape[0]\n",
    "yTrain\n",
    "learnRate = 0.5\n",
    "batchSize = 10\n",
    "totalBatches = (xTrain.shape[0]//batchSize)\n",
    "epochs = 5\n",
    "\n",
    "nClasses = 2\n",
    "nLength = xTrain.shape[1]\n",
    "inputShape = (nLength,1)\n",
    "# xTrainDataSet = tf.data.Dataset.from_tensors(xTrain)\n",
    "# xTrainIter = xTrainDataSet.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "#https://arxiv.org/pdf/1709.05206.pdf LSTM-FCN\n",
    "sellModelConv = Sequential()\n",
    "sellModelConv.add(Conv1D(8,kernel_size= 1, strides=1,\n",
    "                 input_shape=inputShape,\n",
    "                 batch_size = None\n",
    "                   ))\n",
    "sellModelConv.add(BatchNormalization())\n",
    "sellModelConv.add(Activation('relu'))\n",
    "\n",
    "\n",
    "sellModelConv.add(Conv1D(4, kernel_size= 2, strides=1))\n",
    "sellModelConv.add(BatchNormalization())\n",
    "sellModelConv.add(Activation('relu'))\n",
    "\n",
    "sellModelConv.add(Conv1D(8,kernel_size= 2, strides=1))\n",
    "sellModelConv.add(BatchNormalization())\n",
    "sellModelConv.add(Activation('relu'))\n",
    "\n",
    "sellModelConv.add(GlobalAveragePooling1D())\n",
    "# convInput = Input(shape=(None,8))\n",
    "im = sellModelConv.layers[0].input\n",
    "sellConvInput = sellModelConv(im)\n",
    " ########################################\n",
    "sellModelLSTM = Sequential()\n",
    "sellModelLSTM.add(Permute((2, 1), input_shape=inputShape))\n",
    "sellModelLSTM.add(LSTM(4))\n",
    "sellModelLSTM.add(Dropout(0.5))\n",
    "im2 = sellModelLSTM.layers[0].input\n",
    "sellLstmInput = sellModelLSTM(im2)\n",
    "#############################\n",
    "\n",
    "merged = concatenate([sellConvInput, sellLstmInput])\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "sellModel = Model(inputs=[im,im2],outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_4_input (InputLayer)     (None, 30, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_2_input (InputLayer)    (None, 30, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 8)            236         conv1d_4_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 4)            560         permute_2_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12)           0           sequential_3[1][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            13          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 809\n",
      "Trainable params: 769\n",
      "Non-trainable params: 40\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sellModel.summary()\n",
    "sellModel.compile(loss=binary_crossentropy,\n",
    "              optimizer=SGD(lr=learnRate),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 137119 samples, validate on 45707 samples\n",
      "Epoch 1/3\n",
      "137119/137119 [==============================] - 26s 188us/step - loss: 0.6078 - acc: 0.6752 - val_loss: 0.5521 - val_acc: 0.7111\n",
      "Epoch 2/3\n",
      "137119/137119 [==============================] - 23s 171us/step - loss: 0.5969 - acc: 0.6880 - val_loss: 0.5743 - val_acc: 0.7032\n",
      "Epoch 3/3\n",
      "137119/137119 [==============================] - 24s 171us/step - loss: 0.5964 - acc: 0.6876 - val_loss: 0.5990 - val_acc: 0.6935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febb62dbe48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sellModel.fit(x=[xTrain,xTrain],\n",
    "             y=yTrain, \n",
    "             class_weight=classWeight,\n",
    "             validation_data = ([xVal,xVal],yVal),\n",
    "             epochs = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.608225554768\n",
      "Test accuracy: 0.682632667126\n"
     ]
    }
   ],
   "source": [
    "score = sellModel.evaluate([xTest,xTest], yTest, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buyModel.save('buyModel.h5')\n",
    "sellModel.save('sellModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement backtester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import backtrader as bt\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basic API setup\n",
    "# kite = KiteConnect(api_key=\"l3zela16irfa6rax\")\n",
    "# data = kite.request_access_token(\"ldcuznh4fqg5k2w0hrtdubmga4xr43q6\", secret=\"qefc9t3ovposnzvvy94k3sckna7vwuxs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# endDate = utc.localize(dt.datetime(2017,3,31))\n",
    "# # endDate+dt.timedelta(days=1)\n",
    "# # endDate\n",
    "# finDat = dat[(dat['datetime'] > endDate+dt.timedelta(days=1)) & (dat['datetime'] < endDate+dt.timedelta(days=7))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class neuralModel(bt.Indicator):\n",
    "    lines = ('Ind',)\n",
    "    params = (('period', 30),('neuralModel',None))\n",
    "\n",
    "    def __init__(self):\n",
    "        self.addminperiod(self.params.period)\n",
    "        self.i = 0\n",
    "\n",
    "    def next(self):\n",
    "        data = self.data.get(size=self.p.period) # get the data\n",
    "        data = np.array(data) # put it in a numpy array\n",
    "        data = skp.scale(data)\n",
    "        data = data.reshape(1, -1,1) # get it ready for the neural network\n",
    "        self.lines.Ind[0] = np.rint(self.p.neuralModel.predict([data,data])) # predict and round to 0 for no action and 1 for buy\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestStrategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('lagPeriod', lag),\n",
    "        ('buyNeural',buyModel),\n",
    "        ('SellNeural',sellModel)\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.dataclose = self.datas[0].close\n",
    "        \n",
    "        self.neuralBuy = neuralModel(\n",
    "            self.datas[0], \n",
    "            period=self.params.lagPeriod, \n",
    "            neuralModel = self.params.buyNeural\n",
    "        )\n",
    "        \n",
    "        self.neuralSell = neuralModel(\n",
    "            self.datas[0], \n",
    "            period=self.params.lagPeriod, \n",
    "            neuralModel = self.params.SellNeural\n",
    "        )\n",
    "\n",
    "\n",
    "    def next(self):\n",
    "\n",
    "        if self.neuralBuy[0] == 1: \n",
    "            buyOrd = self.buy_bracket(limitprice=self.dataclose+0.4,\n",
    "                                      price=self.dataclose,\n",
    "                                      stopprice=self.dataclose-0.5,\n",
    "                                      size = 200,\n",
    "                                      valid = 0\n",
    "                                     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        elif self.neuralSell[0] == 1:\n",
    "            sellOrd = self.sell_bracket(limitprice=self.dataclose-0.3,\n",
    "                          price=self.dataclose,\n",
    "                          stopprice=self.dataclose+0.5,\n",
    "                          size = 200,\n",
    "                          valid = 0)\n",
    "\n",
    "\n",
    "#     def stop(self):\n",
    "#         self.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import backtrader.plot as pLaut\n",
    "class Plotter(pLaut.Plot):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()  # custom color for volume up bars \n",
    "\n",
    "    def show(self):\n",
    "        mng = plt\n",
    "        title = str(backTestStart.date()) + \" to \" + str(backTestEnd.date())\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"plots/\" + title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Portfolio Value: 10000.00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required by the scale function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-60ca2fa3769a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# cerebro.addanalyzer(bt.analyzers.Returns , _name='Returns')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting Portfolio Value: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcerebro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mthestrats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcerebro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# cerebro.addobserver(bt.observers.Broker)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# cerebro.addobserver(bt.observers.Value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/backtrader/cerebro.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m             \u001b[0;31m# let's skip process \"spawning\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0miterstrat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterstrats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m                 \u001b[0mrunstrat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunstrategies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterstrat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunstrats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunstrat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/backtrader/cerebro.py\u001b[0m in \u001b[0;36mrunstrategies\u001b[0;34m(self, iterstrat, predata)\u001b[0m\n\u001b[1;32m   1288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runonce_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunstrats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runonce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunstrats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldsync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/backtrader/cerebro.py\u001b[0m in \u001b[0;36m_runonce\u001b[0;34m(self, runstrats)\u001b[0m\n\u001b[1;32m   1646\u001b[0m         '''\n\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstrat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrunstrats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m             \u001b[0mstrat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0mstrat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# strat called next by next - reset lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/backtrader/lineiterator.py\u001b[0m in \u001b[0;36m_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lineiterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLineIterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mindicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobserver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lineiterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLineIterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObsType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/backtrader/lineiterator.py\u001b[0m in \u001b[0;36m_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;31m# indicators are each called with its min period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreonce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minperiod\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moncestart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minperiod\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minperiod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minperiod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/backtrader/indicator.py\u001b[0m in \u001b[0;36moncestart_via_nextstart\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0monce_via_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/backtrader/lineiterator.py\u001b[0m in \u001b[0;36mnextstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Called once for 1st full calculation - defaults to regular next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-bb21250c641c>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put it in a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get it ready for the neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuralModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# predict and round to 0 for no action and 1 for buy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mscale\u001b[0;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[1;32m    131\u001b[0m     X = check_array(X, accept_sparse='csc', copy=copy, ensure_2d=False,\n\u001b[1;32m    132\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'the scale function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AlgoTrading/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    429\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 431\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required by the scale function."
     ]
    }
   ],
   "source": [
    "fed = bt.feeds.GenericCSVData(dataname='data/HFCL.csv',\n",
    "                              dtformat=\"%Y-%m-%dT%H:%M:%S%z\",\n",
    "                              openinterest=-1,\n",
    "                              headers=False,\n",
    "                              fromdate= backTestStart,\n",
    "                              todate= backTestEnd,\n",
    "#                               timeframe=bt.TimeFrame.Minutes,\n",
    "#                               tzinput = pytz.timezone('Asia/Kolkata'),\n",
    "                              plot=False)\n",
    "\n",
    "\n",
    "cerebro = bt.Cerebro()\n",
    "cerebro.broker.setcommission(commission=0.0001)\n",
    "cerebro.adddata(fed)\n",
    "cerebro.addstrategy(TestStrategy)\n",
    "cerebro.addobserver(bt.observers.Value)\n",
    "# cerebro.addanalyzer(bt.analyzers.Returns , _name='Returns')\n",
    "print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "thestrats = cerebro.run(stdstats=False)\n",
    "# cerebro.addobserver(bt.observers.Broker)\n",
    "# cerebro.addobserver(bt.observers.Value)\n",
    "thestrat = thestrats[0]\n",
    "\n",
    "# print('Sharpe Ratio:', thestrat.analyzers.Returns.get_analysis())\n",
    "\n",
    "print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "cerebro.plot(start=backTestStart , end=backTestEnd,plotter = Plotter())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Actual Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kiteconnect import KiteConnect\n",
    "from time import sleep\n",
    "import json\n",
    "import paho.mqtt.client as mqtt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lastPrice = \"\"\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"Connected with result code \"+str(rc))\n",
    "\n",
    "    # Subscribing in on_connect() means that if we lose the connection and\n",
    "    # reconnect then subscriptions will be renewed.\n",
    "    client.subscribe(\"priceData\")\n",
    "\n",
    "# The callback for when a PUBLISH message is received from the server.\n",
    "def on_message(client, userdata, message):\n",
    "    global lastPrice\n",
    "    lastPrice = message\n",
    "    client.loop_stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = load_model('buyModel.h5')\n",
    "s = load_model('sellModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateLastPrice():\n",
    "    client = mqtt.Client() # connect\n",
    "    client.on_connect = on_connect # print connected\n",
    "    client.on_message = on_message # update message\n",
    "    client.connect(\"localhost\", 1883, 60)\n",
    "    client.loop_start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = 1\n",
    "lastPrice = np.zeros(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if start == 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:AlgoTrading]",
   "language": "python",
   "name": "conda-env-AlgoTrading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
