{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setup\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "import time\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from pythonLib.helper import *\n",
    "import sqlalchemy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "DATA_DIR = 'data' \n",
    "np.random.seed(seed)\n",
    "dbString = 'postgresql://s2c:JANver95@localhost:5432/stockdata'\n",
    "engine = sqlalchemy.create_engine(dbString) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data into postgres\n",
    "\n",
    "We need to load the data into a postgres database. First, we go through each file appending the file name as an added column, then we store each file into the database under the HistoricalData table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Loads everything into postgres, Uncomment if needed\n",
    "# # i = 0\n",
    "# for each_csv in os.listdir(DATA_DIR):\n",
    "#     i = i+1\n",
    "#     File = os.path.join(DATA_DIR,each_csv)\n",
    "#     try:\n",
    "#         dataInit = readData(File)\n",
    "#     except:\n",
    "#         print(each_csv)\n",
    "#     height = np.shape(dataInit)[0]\n",
    "#     width = 1\n",
    "#     tickers = pd.DataFrame(each_csv[:-4], index=range(height), columns=range(width))\n",
    "#     tickers.columns = ['ticker']\n",
    "#     dataInit = tickers.join(dataInit)\n",
    "#     dataInit['datetime'] = dataInit['datetime'].apply(lambda d: str(d))\n",
    "#     engine = sqlalchemy.create_engine('postgresql://s2c:JANver95@localhost:5432/stockdata')\n",
    "#     dataInit.to_sql(\"histdata\",engine,index = False,dtype={'datetime':sqlalchemy.TIMESTAMP(timezone=True)},if_exists='append')\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Database, retrieve a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT ticker,avg(volume) FROM histdata GROUP BY ticker ORDER BY avg DESC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DLF</td>\n",
       "      <td>27371.004363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEDERALBNK</td>\n",
       "      <td>20092.896278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>19765.357590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HINDPETRO</td>\n",
       "      <td>17819.197704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JSWSTEEL</td>\n",
       "      <td>17499.262486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TV18BRDCST</td>\n",
       "      <td>13962.737137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TATAPOWER</td>\n",
       "      <td>11868.993745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HFCL</td>\n",
       "      <td>10676.823751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RASOYPR</td>\n",
       "      <td>9808.606920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JSWENERGY</td>\n",
       "      <td>8716.109570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JETAIRWAYS</td>\n",
       "      <td>7489.075365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BIOCON</td>\n",
       "      <td>6716.137971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ENGINERSIN</td>\n",
       "      <td>5892.256919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TATAGLOBAL</td>\n",
       "      <td>5399.916206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IOB</td>\n",
       "      <td>5313.062931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TVSMOTOR</td>\n",
       "      <td>4879.846055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>JKTYRE</td>\n",
       "      <td>4840.082494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>REIAGROLTD</td>\n",
       "      <td>4663.438280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BALRAMCHIN</td>\n",
       "      <td>3763.878738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DABUR</td>\n",
       "      <td>3708.886975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>INDUSINDBK</td>\n",
       "      <td>3152.410407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>INDOSOLAR</td>\n",
       "      <td>2739.779306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TRIDENT</td>\n",
       "      <td>2660.728354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HINDNATGLS</td>\n",
       "      <td>2108.936009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TAJGVK-BL</td>\n",
       "      <td>1988.299893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SPARC</td>\n",
       "      <td>1899.156814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BFUTILITIE</td>\n",
       "      <td>1845.213332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BEPL</td>\n",
       "      <td>1840.589361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LYCOS-BE</td>\n",
       "      <td>1619.864635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ASTRAMICRO</td>\n",
       "      <td>1337.472871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ALFAICA</td>\n",
       "      <td>5.997923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>TCIDEVELOP</td>\n",
       "      <td>4.300657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>TITANBIO</td>\n",
       "      <td>4.066773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>830PFC2027</td>\n",
       "      <td>3.612517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>SPARCSYS</td>\n",
       "      <td>3.414989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>HDFCMFGETF</td>\n",
       "      <td>3.408039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>CONTPTR</td>\n",
       "      <td>3.397543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>MNPLFIN</td>\n",
       "      <td>3.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>SUMMITSEC</td>\n",
       "      <td>3.206094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>TIDEWATER</td>\n",
       "      <td>2.736097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>PKTEA</td>\n",
       "      <td>2.698015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>RELCNX100</td>\n",
       "      <td>2.626015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>GGDANDE</td>\n",
       "      <td>2.543360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0MFL2020A</td>\n",
       "      <td>1.482456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>GRPLTD</td>\n",
       "      <td>1.394168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>SRTRANSFIN-NW</td>\n",
       "      <td>1.131730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>WENDT</td>\n",
       "      <td>1.038028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>IRFC-N9</td>\n",
       "      <td>0.990990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>722REC22TF</td>\n",
       "      <td>0.957686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>IDBIGOLD</td>\n",
       "      <td>0.914974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0SIFL20</td>\n",
       "      <td>0.898160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>SRIVAJRA</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>TRANSASIA</td>\n",
       "      <td>0.568123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>841IREDA24</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>853MMFSL23</td>\n",
       "      <td>0.183056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0SEFL20B</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ACME</td>\n",
       "      <td>0.109312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>HDFCNIFETF</td>\n",
       "      <td>0.041339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>843IDFBKA</td>\n",
       "      <td>0.035398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>SPECTACLE-BE</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ticker           avg\n",
       "0              DLF  27371.004363\n",
       "1       FEDERALBNK  20092.896278\n",
       "2         RELIANCE  19765.357590\n",
       "3        HINDPETRO  17819.197704\n",
       "4         JSWSTEEL  17499.262486\n",
       "5       TV18BRDCST  13962.737137\n",
       "6        TATAPOWER  11868.993745\n",
       "7             HFCL  10676.823751\n",
       "8          RASOYPR   9808.606920\n",
       "9        JSWENERGY   8716.109570\n",
       "10      JETAIRWAYS   7489.075365\n",
       "11          BIOCON   6716.137971\n",
       "12      ENGINERSIN   5892.256919\n",
       "13      TATAGLOBAL   5399.916206\n",
       "14             IOB   5313.062931\n",
       "15        TVSMOTOR   4879.846055\n",
       "16          JKTYRE   4840.082494\n",
       "17      REIAGROLTD   4663.438280\n",
       "18      BALRAMCHIN   3763.878738\n",
       "19           DABUR   3708.886975\n",
       "20      INDUSINDBK   3152.410407\n",
       "21       INDOSOLAR   2739.779306\n",
       "22         TRIDENT   2660.728354\n",
       "23      HINDNATGLS   2108.936009\n",
       "24       TAJGVK-BL   1988.299893\n",
       "25           SPARC   1899.156814\n",
       "26      BFUTILITIE   1845.213332\n",
       "27            BEPL   1840.589361\n",
       "28        LYCOS-BE   1619.864635\n",
       "29      ASTRAMICRO   1337.472871\n",
       "..             ...           ...\n",
       "181        ALFAICA      5.997923\n",
       "182     TCIDEVELOP      4.300657\n",
       "183       TITANBIO      4.066773\n",
       "184     830PFC2027      3.612517\n",
       "185       SPARCSYS      3.414989\n",
       "186     HDFCMFGETF      3.408039\n",
       "187        CONTPTR      3.397543\n",
       "188        MNPLFIN      3.225806\n",
       "189      SUMMITSEC      3.206094\n",
       "190      TIDEWATER      2.736097\n",
       "191          PKTEA      2.698015\n",
       "192      RELCNX100      2.626015\n",
       "193        GGDANDE      2.543360\n",
       "194      0MFL2020A      1.482456\n",
       "195         GRPLTD      1.394168\n",
       "196  SRTRANSFIN-NW      1.131730\n",
       "197          WENDT      1.038028\n",
       "198        IRFC-N9      0.990990\n",
       "199     722REC22TF      0.957686\n",
       "200       IDBIGOLD      0.914974\n",
       "201        0SIFL20      0.898160\n",
       "202       SRIVAJRA      0.652174\n",
       "203      TRANSASIA      0.568123\n",
       "204     841IREDA24      0.357143\n",
       "205     853MMFSL23      0.183056\n",
       "206       0SEFL20B      0.156250\n",
       "207           ACME      0.109312\n",
       "208     HDFCNIFETF      0.041339\n",
       "209      843IDFBKA      0.035398\n",
       "210   SPECTACLE-BE      0.000000\n",
       "\n",
       "[211 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT ticker,avg(volume) FROM histdata GROUP BY ticker ORDER BY avg DESC\"\n",
    "print(query)\n",
    "stockSet = pd.read_sql(query,engine)\n",
    "\n",
    "stockSet\n",
    "\n",
    "# We use this to select DLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM histdata WHERE ticker = 'DLF'\"# or ticker = 'FEDERALBNK' or ticker = 'RELIANCE'\"\n",
    "res = pd.read_sql(query,engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Helper Functions\n",
    "\n",
    "These functions are more or less general functions that should prove to be fairly useful\n",
    "\n",
    "\n",
    "- **ReadData(filename)** : Reads data from Zerodha API historical data files and returns a Pandas DataFrame\n",
    "- **sycTimeSeries(ts1,ts2)** : Making sure that 2 timeseries are synced to the smaller time series\n",
    "- **timeseriesLagged(data, lag=60)**: Creates Lagged series.Goes through a series and generates an lag+1  dimensional   pandas DataFrame that has each previous lag timeunit.\n",
    "- **binarizeTime(resLagged, rate=0.01)** : Binarizes the last column into 1,-1 or 0 depending whether the price increased, decreased or stayed the same from the beginning to the end of the lag period (triggers on changes by magnitutde = rate*current price).\n",
    "- **findLag(data, targetCorr,suppressed)** :  Finds the right lag given a target correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading some Data and Getting a feel \n",
    "\n",
    "We use an autocorrelation plot to help us figure out what is an optimal amount of lag. We are really looking for a lag that correlates highly. We go through the lags till we reach the last lag that guarantees 0.97 autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup Parameters\n",
    "dataInit = res # Read the stock price data. This is 1 minute data\n",
    "data = dataInit['close'] # extract the 'close' column as a Pandas series\n",
    "# plt.figure()\n",
    "# pd.tools.plotting.lag_plot(data) # Lag plot to check randomness\n",
    "# plt.figure()\n",
    "# pd.tools.plotting.autocorrelation_plot(data) # Auto correlation plot to check if series is autocorrelated at all\n",
    "\n",
    "# # Find the right lag manually\n",
    "# targetCorr = 0.99 # autocorrelation we want\n",
    "# lag = findLag(data,targetCorr,True) # Lag that is indicative \n",
    "# if lag == 99: #if lag is 99 then we can just use any number above it as autocorrelation is guaranteed.\n",
    "#     lag = 120 #nice round 2  hour intervals\n",
    "# print(lag)\n",
    "lag = 120\n",
    "series = timeseriesLagged(data,lag) # Generate the lagged series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binSeries = binarizeTime(series,0.000)\n",
    "change = binSeries.iloc[:,-1]== -1 # convert to binary\n",
    "binSeries.loc[change,'121']=0 # convert to binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171686"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(binSeries.iloc[:,-1] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3692097125637348"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "171686/(171686+126863)\n",
    "0.5750680792767686/0.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training Data\n",
    "\n",
    "Now that we have an idea of what's going on in the dataset, it is a good time to generate training data. We do an 80:20 training:testing split, and then we randomize the training set because we assume that only the last LAG minutes matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as skp\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get values from pandas series as we need a numpy array for our classifier\n",
    "seriesVals = binSeries.values\n",
    "trainPercent = 0.8 # first 80% of the data is used for training\n",
    "\n",
    "#Split into train and test\n",
    "trainBegin = int(trainPercent*len(seriesVals)) \n",
    "trains = seriesVals[0:trainBegin]\n",
    "train,val = train_test_split(trains)\n",
    "test = seriesVals[trainBegin:]\n",
    "np.random.shuffle(train) # shuffle the training dataset\n",
    "\n",
    "# Split into x and y\n",
    "xTrain,yTrain = train[:,0:-1],train[:,-1] # X is the first lag elements. Y is the lag+1 element\n",
    "xVal,yVal = val[:,0:-1],val[:,-1] # Same for Validation\n",
    "xTest,yTest = test[:,0:-1],test[:,-1] # Same for testing data\n",
    "\n",
    "#scale function\n",
    "a = lambda row: ((row-np.min(row))/(np.max(row)-np.min(row)))\n",
    "xTrain = np.apply_along_axis(a,1,xTrain) #scale to 01\n",
    "xTest = np.apply_along_axis(a,1,xTest) #scale to 0 1\n",
    "xVal = np.apply_along_axis(a,1,xVal) #scale to 0 1\n",
    "\n",
    "#Reshape for keras\n",
    "xTrain = xTrain.reshape(xTrain.shape[0], xTrain.shape[1])\n",
    "xTest = xTest.reshape(xTest.shape[0], xTest.shape[1])\n",
    "xVal = xVal.reshape(xVal.shape[0],xVal.shape[1])\n",
    "\n",
    "\n",
    "# # # encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(yTrain)\n",
    "encodedyTrain = encoder.transform(yTrain)\n",
    "encodedyTest = encoder.transform(yTest)\n",
    "encodedyVal = encoder.transform(yVal)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "yTrain = np_utils.to_categorical(encodedyTrain)\n",
    "yTest = np_utils.to_categorical(encodedyTest)\n",
    "yVal = np_utils.to_categorical(encodedyVal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classifier\n",
    "\n",
    "A simple CNN to see how it works with just basic stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fixed\n",
    "nClasses = 2\n",
    "n_channels = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, xTrain.shape[-1]])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, nClasses])\n",
    "\n",
    "def varGen(shape, bias = False):\n",
    "    if bias:\n",
    "        initial = tf.constant(0.1, shape = shape)\n",
    "    else:\n",
    "        initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial) \n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "def meanPool(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 1, 2, 1], #,pooling_type = \"AVG\",\n",
    "                        strides=[1, 1, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "    with tf.name_scope('reshape'):\n",
    "        xImage = tf.reshape(x, [-1, 1, xTrain.shape[-1], 1])\n",
    "    \n",
    "    # convolve layer 1 maps 120 time to 300 features\n",
    "    with tf.name_scope('conv1'):\n",
    "        wConv1 = varGen([12, 1, 1, 300])\n",
    "        bConv1 = varGen([300],bias=True)\n",
    "        hConv1 = tf.nn.relu(conv2d(xImage, wConv1) + bConv1)\n",
    "    \n",
    "    # pool 2x downsample\n",
    "    with tf.name_scope('pool1'):\n",
    "        hPool1 = meanPool(hConv1)\n",
    "        \n",
    "    # convolve layer 2 maps 60 features to 120 features\n",
    "    with tf.name_scope('conv2'): \n",
    "        wConv2 = varGen([12, 1, 300, 120])\n",
    "        bConv2 = varGen([120],bias = True)\n",
    "        hConv2 = tf.nn.relu(conv2d(hPool1, wConv2) + bConv2)\n",
    "        \n",
    "    # downsample 2x again\n",
    "    with tf.name_scope('pool2'):\n",
    "        hPool2 = meanPool(hConv2)\n",
    "    \n",
    "    # convolve layer 3\n",
    "    with tf.name_scope('conv3'):\n",
    "        wConv3 = varGen([12, 1, 120, 60])\n",
    "        bConv3 = varGen([60],bias=True)\n",
    "        hConv3 = tf.nn.relu(conv2d(hPool2, wConv3) + bConv3)\n",
    "    \n",
    "    # pool 2x downsample\n",
    "    with tf.name_scope('pool3'):\n",
    "        hPool3 = meanPool(hConv3)\n",
    "    #print(hPool3) \n",
    "    \n",
    "    # convolve layer 4\n",
    "    with tf.name_scope('conv4'):\n",
    "        wConv4 = varGen([12, 1, 60, 60])\n",
    "        bConv4 = varGen([60],bias=True)\n",
    "        hConv4 = tf.nn.relu(conv2d(hPool3, wConv4) + bConv4)\n",
    "    \n",
    "    # pool 2x downsample\n",
    "    with tf.name_scope('pool4'):\n",
    "        hPool4 = meanPool(hConv4)\n",
    "    #print(hPool4)     \n",
    "    \n",
    "    with tf.name_scope('fc1'):\n",
    "        wFC1 = varGen([8*60,120])\n",
    "        bFC1 = varGen([120],bias = True)\n",
    "        hPool4Flat = tf.reshape(hPool4,[-1,8*60])\n",
    "        hFC1 = tf.nn.relu(tf.matmul(hPool4Flat,wFC1)+bFC1)\n",
    "        \n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        hFC1Drop = tf.nn.dropout(hFC1, keep_prob)\n",
    "        \n",
    "    # output as classes\n",
    "    with tf.name_scope('fc2'):\n",
    "        wFC2 = varGen([120,nClasses])\n",
    "        bFC2 = varGen([nClasses],bias = True)\n",
    "        \n",
    "        yConv = tf.matmul(hFC1Drop,wFC2) + bFC2\n",
    "    return yConv,keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,xTrain.shape[-1]])\n",
    "y_ = tf.placeholder(tf.float32,[None,nClasses])\n",
    "yConv,keep_prob = deepnn(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph to: /tmp/tmp8kwaxuuk\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    class_weights = tf.constant([[1.35, 1.0]])\n",
    "    weights = tf.reduce_sum(class_weights*y_,axis=1)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "                                                            logits=yConv)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy * weights)\n",
    "\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(yConv, 1), tf.argmax(y_, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    \n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "\n",
    "graph_location = tempfile.mkdtemp()\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph())\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.46\n",
      "Model saved in file: models/model_n0.ckpt\n",
      "step 1, training accuracy 0.56\n",
      "Model saved in file: models/model_n10.ckpt\n",
      "step 2, training accuracy 0.58\n",
      "Model saved in file: models/model_n20.ckpt\n",
      "step 3, training accuracy 0.6\n",
      "Model saved in file: models/model_n30.ckpt\n",
      "step 4, training accuracy 0.58\n",
      "Model saved in file: models/model_n40.ckpt\n",
      "step 5, training accuracy 0.56\n",
      "Model saved in file: models/model_n50.ckpt\n",
      "step 6, training accuracy 0.58\n",
      "Model saved in file: models/model_n60.ckpt\n",
      "step 7, training accuracy 0.42\n",
      "Model saved in file: models/model_n70.ckpt\n",
      "step 8, training accuracy 0.58\n",
      "Model saved in file: models/model_n80.ckpt\n",
      "step 9, training accuracy 0.62\n",
      "Model saved in file: models/model_n90.ckpt\n",
      "step 10, training accuracy 0.66\n",
      "Model saved in file: models/model_n100.ckpt\n",
      "step 11, training accuracy 0.46\n",
      "Model saved in file: models/model_n110.ckpt\n",
      "step 12, training accuracy 0.56\n",
      "Model saved in file: models/model_n120.ckpt\n",
      "step 13, training accuracy 0.58\n",
      "Model saved in file: models/model_n130.ckpt\n",
      "step 14, training accuracy 0.62\n",
      "Model saved in file: models/model_n140.ckpt\n",
      "step 15, training accuracy 0.54\n",
      "Model saved in file: models/model_n150.ckpt\n",
      "step 16, training accuracy 0.6\n",
      "Model saved in file: models/model_n160.ckpt\n",
      "step 17, training accuracy 0.56\n",
      "Model saved in file: models/model_n170.ckpt\n",
      "step 18, training accuracy 0.6\n",
      "Model saved in file: models/model_n180.ckpt\n",
      "step 19, training accuracy 0.56\n",
      "Model saved in file: models/model_n190.ckpt\n",
      "step 20, training accuracy 0.66\n",
      "Model saved in file: models/model_n200.ckpt\n",
      "step 21, training accuracy 0.48\n",
      "Model saved in file: models/model_n210.ckpt\n",
      "step 22, training accuracy 0.58\n",
      "Model saved in file: models/model_n220.ckpt\n",
      "step 23, training accuracy 0.58\n",
      "Model saved in file: models/model_n230.ckpt\n",
      "step 24, training accuracy 0.5\n",
      "Model saved in file: models/model_n240.ckpt\n",
      "step 25, training accuracy 0.58\n",
      "Model saved in file: models/model_n250.ckpt\n",
      "step 26, training accuracy 0.68\n",
      "Model saved in file: models/model_n260.ckpt\n",
      "step 27, training accuracy 0.58\n",
      "Model saved in file: models/model_n270.ckpt\n",
      "step 28, training accuracy 0.6\n",
      "Model saved in file: models/model_n280.ckpt\n",
      "step 29, training accuracy 0.52\n",
      "Model saved in file: models/model_n290.ckpt\n",
      "step 30, training accuracy 0.48\n",
      "Model saved in file: models/model_n300.ckpt\n",
      "step 31, training accuracy 0.52\n",
      "Model saved in file: models/model_n310.ckpt\n",
      "step 32, training accuracy 0.6\n",
      "Model saved in file: models/model_n320.ckpt\n",
      "step 33, training accuracy 0.56\n",
      "Model saved in file: models/model_n330.ckpt\n",
      "step 34, training accuracy 0.6\n",
      "Model saved in file: models/model_n340.ckpt\n",
      "step 35, training accuracy 0.54\n",
      "Model saved in file: models/model_n350.ckpt\n",
      "step 36, training accuracy 0.64\n",
      "Model saved in file: models/model_n360.ckpt\n",
      "step 37, training accuracy 0.66\n",
      "Model saved in file: models/model_n370.ckpt\n",
      "step 38, training accuracy 0.54\n",
      "Model saved in file: models/model_n380.ckpt\n",
      "step 39, training accuracy 0.52\n",
      "Model saved in file: models/model_n390.ckpt\n",
      "step 40, training accuracy 0.6\n",
      "Model saved in file: models/model_n400.ckpt\n",
      "step 41, training accuracy 0.64\n",
      "Model saved in file: models/model_n410.ckpt\n",
      "step 42, training accuracy 0.6\n",
      "Model saved in file: models/model_n420.ckpt\n",
      "step 43, training accuracy 0.56\n",
      "Model saved in file: models/model_n430.ckpt\n",
      "step 44, training accuracy 0.56\n",
      "Model saved in file: models/model_n440.ckpt\n",
      "step 45, training accuracy 0.64\n",
      "Model saved in file: models/model_n450.ckpt\n",
      "step 46, training accuracy 0.68\n",
      "Model saved in file: models/model_n460.ckpt\n",
      "step 47, training accuracy 0.58\n",
      "Model saved in file: models/model_n470.ckpt\n",
      "step 48, training accuracy 0.6\n",
      "Model saved in file: models/model_n480.ckpt\n",
      "step 49, training accuracy 0.54\n",
      "Model saved in file: models/model_n490.ckpt\n",
      "step 50, training accuracy 0.58\n",
      "Model saved in file: models/model_n500.ckpt\n",
      "step 51, training accuracy 0.58\n",
      "Model saved in file: models/model_n510.ckpt\n",
      "step 52, training accuracy 0.56\n",
      "Model saved in file: models/model_n520.ckpt\n",
      "step 53, training accuracy 0.58\n",
      "Model saved in file: models/model_n530.ckpt\n",
      "step 54, training accuracy 0.6\n",
      "Model saved in file: models/model_n540.ckpt\n",
      "step 55, training accuracy 0.5\n",
      "Model saved in file: models/model_n550.ckpt\n",
      "step 56, training accuracy 0.56\n",
      "Model saved in file: models/model_n560.ckpt\n",
      "step 57, training accuracy 0.56\n",
      "Model saved in file: models/model_n570.ckpt\n",
      "step 58, training accuracy 0.48\n",
      "Model saved in file: models/model_n580.ckpt\n",
      "step 59, training accuracy 0.7\n",
      "Model saved in file: models/model_n590.ckpt\n",
      "step 60, training accuracy 0.56\n",
      "Model saved in file: models/model_n600.ckpt\n",
      "step 61, training accuracy 0.56\n",
      "Model saved in file: models/model_n610.ckpt\n",
      "step 62, training accuracy 0.7\n",
      "Model saved in file: models/model_n620.ckpt\n",
      "step 63, training accuracy 0.5\n",
      "Model saved in file: models/model_n630.ckpt\n",
      "step 64, training accuracy 0.56\n",
      "Model saved in file: models/model_n640.ckpt\n",
      "step 65, training accuracy 0.72\n",
      "Model saved in file: models/model_n650.ckpt\n",
      "step 66, training accuracy 0.56\n",
      "Model saved in file: models/model_n660.ckpt\n",
      "step 67, training accuracy 0.62\n",
      "Model saved in file: models/model_n670.ckpt\n",
      "step 68, training accuracy 0.64\n",
      "Model saved in file: models/model_n680.ckpt\n",
      "step 69, training accuracy 0.58\n",
      "Model saved in file: models/model_n690.ckpt\n",
      "step 70, training accuracy 0.64\n",
      "Model saved in file: models/model_n700.ckpt\n",
      "step 71, training accuracy 0.62\n",
      "Model saved in file: models/model_n710.ckpt\n",
      "step 72, training accuracy 0.56\n",
      "Model saved in file: models/model_n720.ckpt\n",
      "step 73, training accuracy 0.54\n",
      "Model saved in file: models/model_n730.ckpt\n",
      "step 74, training accuracy 0.62\n",
      "Model saved in file: models/model_n740.ckpt\n",
      "step 75, training accuracy 0.58\n",
      "Model saved in file: models/model_n750.ckpt\n",
      "step 76, training accuracy 0.6\n",
      "Model saved in file: models/model_n760.ckpt\n",
      "step 77, training accuracy 0.72\n",
      "Model saved in file: models/model_n770.ckpt\n",
      "step 78, training accuracy 0.64\n",
      "Model saved in file: models/model_n780.ckpt\n",
      "step 79, training accuracy 0.54\n",
      "Model saved in file: models/model_n790.ckpt\n",
      "step 80, training accuracy 0.5\n",
      "Model saved in file: models/model_n800.ckpt\n",
      "step 81, training accuracy 0.5\n",
      "Model saved in file: models/model_n810.ckpt\n",
      "step 82, training accuracy 0.64\n",
      "Model saved in file: models/model_n820.ckpt\n",
      "step 83, training accuracy 0.52\n",
      "Model saved in file: models/model_n830.ckpt\n",
      "step 84, training accuracy 0.54\n",
      "Model saved in file: models/model_n840.ckpt\n",
      "step 85, training accuracy 0.66\n",
      "Model saved in file: models/model_n850.ckpt\n",
      "step 86, training accuracy 0.42\n",
      "Model saved in file: models/model_n860.ckpt\n",
      "step 87, training accuracy 0.58\n",
      "Model saved in file: models/model_n870.ckpt\n",
      "step 88, training accuracy 0.58\n",
      "Model saved in file: models/model_n880.ckpt\n",
      "step 89, training accuracy 0.5\n",
      "Model saved in file: models/model_n890.ckpt\n",
      "step 90, training accuracy 0.64\n",
      "Model saved in file: models/model_n900.ckpt\n",
      "step 91, training accuracy 0.64\n",
      "Model saved in file: models/model_n910.ckpt\n",
      "step 92, training accuracy 0.62\n",
      "Model saved in file: models/model_n920.ckpt\n",
      "step 93, training accuracy 0.64\n",
      "Model saved in file: models/model_n930.ckpt\n",
      "step 94, training accuracy 0.78\n",
      "Model saved in file: models/model_n940.ckpt\n",
      "step 95, training accuracy 0.62\n",
      "Model saved in file: models/model_n950.ckpt\n",
      "step 96, training accuracy 0.4\n",
      "Model saved in file: models/model_n960.ckpt\n",
      "step 97, training accuracy 0.48\n",
      "Model saved in file: models/model_n970.ckpt\n",
      "step 98, training accuracy 0.5\n",
      "Model saved in file: models/model_n980.ckpt\n",
      "step 99, training accuracy 0.56\n",
      "Model saved in file: models/model_n990.ckpt\n",
      "step 100, training accuracy 0.54\n",
      "Model saved in file: models/model_n1000.ckpt\n",
      "step 101, training accuracy 0.66\n",
      "Model saved in file: models/model_n1010.ckpt\n",
      "step 102, training accuracy 0.56\n",
      "Model saved in file: models/model_n1020.ckpt\n",
      "step 103, training accuracy 0.42\n",
      "Model saved in file: models/model_n1030.ckpt\n",
      "step 104, training accuracy 0.56\n",
      "Model saved in file: models/model_n1040.ckpt\n",
      "step 105, training accuracy 0.56\n",
      "Model saved in file: models/model_n1050.ckpt\n",
      "step 106, training accuracy 0.52\n",
      "Model saved in file: models/model_n1060.ckpt\n",
      "step 107, training accuracy 0.58\n",
      "Model saved in file: models/model_n1070.ckpt\n",
      "step 108, training accuracy 0.5\n",
      "Model saved in file: models/model_n1080.ckpt\n",
      "step 109, training accuracy 0.6\n",
      "Model saved in file: models/model_n1090.ckpt\n",
      "step 110, training accuracy 0.68\n",
      "Model saved in file: models/model_n1100.ckpt\n",
      "step 111, training accuracy 0.48\n",
      "Model saved in file: models/model_n1110.ckpt\n",
      "step 112, training accuracy 0.6\n",
      "Model saved in file: models/model_n1120.ckpt\n",
      "step 113, training accuracy 0.56\n",
      "Model saved in file: models/model_n1130.ckpt\n",
      "step 114, training accuracy 0.46\n",
      "Model saved in file: models/model_n1140.ckpt\n",
      "step 115, training accuracy 0.62\n",
      "Model saved in file: models/model_n1150.ckpt\n",
      "step 116, training accuracy 0.56\n",
      "Model saved in file: models/model_n1160.ckpt\n",
      "step 117, training accuracy 0.52\n",
      "Model saved in file: models/model_n1170.ckpt\n",
      "step 118, training accuracy 0.54\n",
      "Model saved in file: models/model_n1180.ckpt\n",
      "step 119, training accuracy 0.6\n",
      "Model saved in file: models/model_n1190.ckpt\n",
      "step 120, training accuracy 0.48\n",
      "Model saved in file: models/model_n1200.ckpt\n",
      "step 121, training accuracy 0.64\n",
      "Model saved in file: models/model_n1210.ckpt\n",
      "step 122, training accuracy 0.5\n",
      "Model saved in file: models/model_n1220.ckpt\n",
      "step 123, training accuracy 0.62\n",
      "Model saved in file: models/model_n1230.ckpt\n",
      "step 124, training accuracy 0.58\n",
      "Model saved in file: models/model_n1240.ckpt\n",
      "step 125, training accuracy 0.62\n",
      "Model saved in file: models/model_n1250.ckpt\n",
      "step 126, training accuracy 0.6\n",
      "Model saved in file: models/model_n1260.ckpt\n",
      "step 127, training accuracy 0.62\n",
      "Model saved in file: models/model_n1270.ckpt\n",
      "step 128, training accuracy 0.64\n",
      "Model saved in file: models/model_n1280.ckpt\n",
      "step 129, training accuracy 0.58\n",
      "Model saved in file: models/model_n1290.ckpt\n",
      "step 130, training accuracy 0.64\n",
      "Model saved in file: models/model_n1300.ckpt\n",
      "step 131, training accuracy 0.54\n",
      "Model saved in file: models/model_n1310.ckpt\n",
      "step 132, training accuracy 0.66\n",
      "Model saved in file: models/model_n1320.ckpt\n",
      "step 133, training accuracy 0.64\n",
      "Model saved in file: models/model_n1330.ckpt\n",
      "step 134, training accuracy 0.54\n",
      "Model saved in file: models/model_n1340.ckpt\n",
      "step 135, training accuracy 0.6\n",
      "Model saved in file: models/model_n1350.ckpt\n",
      "step 136, training accuracy 0.44\n",
      "Model saved in file: models/model_n1360.ckpt\n",
      "step 137, training accuracy 0.68\n",
      "Model saved in file: models/model_n1370.ckpt\n",
      "step 138, training accuracy 0.56\n",
      "Model saved in file: models/model_n1380.ckpt\n",
      "step 139, training accuracy 0.7\n",
      "Model saved in file: models/model_n1390.ckpt\n",
      "step 140, training accuracy 0.58\n",
      "Model saved in file: models/model_n1400.ckpt\n",
      "step 141, training accuracy 0.48\n",
      "Model saved in file: models/model_n1410.ckpt\n",
      "step 142, training accuracy 0.5\n",
      "Model saved in file: models/model_n1420.ckpt\n",
      "step 143, training accuracy 0.44\n",
      "Model saved in file: models/model_n1430.ckpt\n",
      "step 144, training accuracy 0.48\n",
      "Model saved in file: models/model_n1440.ckpt\n",
      "step 145, training accuracy 0.6\n",
      "Model saved in file: models/model_n1450.ckpt\n",
      "step 146, training accuracy 0.56\n",
      "Model saved in file: models/model_n1460.ckpt\n",
      "step 147, training accuracy 0.7\n",
      "Model saved in file: models/model_n1470.ckpt\n",
      "step 148, training accuracy 0.52\n",
      "Model saved in file: models/model_n1480.ckpt\n",
      "step 149, training accuracy 0.68\n",
      "Model saved in file: models/model_n1490.ckpt\n",
      "step 150, training accuracy 0.54\n",
      "Model saved in file: models/model_n1500.ckpt\n",
      "step 151, training accuracy 0.52\n",
      "Model saved in file: models/model_n1510.ckpt\n",
      "step 152, training accuracy 0.38\n",
      "Model saved in file: models/model_n1520.ckpt\n",
      "step 153, training accuracy 0.56\n",
      "Model saved in file: models/model_n1530.ckpt\n",
      "step 154, training accuracy 0.52\n",
      "Model saved in file: models/model_n1540.ckpt\n",
      "step 155, training accuracy 0.66\n",
      "Model saved in file: models/model_n1550.ckpt\n",
      "step 156, training accuracy 0.64\n",
      "Model saved in file: models/model_n1560.ckpt\n",
      "step 157, training accuracy 0.66\n",
      "Model saved in file: models/model_n1570.ckpt\n",
      "step 158, training accuracy 0.56\n",
      "Model saved in file: models/model_n1580.ckpt\n",
      "step 159, training accuracy 0.64\n",
      "Model saved in file: models/model_n1590.ckpt\n",
      "step 160, training accuracy 0.58\n",
      "Model saved in file: models/model_n1600.ckpt\n",
      "step 161, training accuracy 0.54\n",
      "Model saved in file: models/model_n1610.ckpt\n",
      "step 162, training accuracy 0.56\n",
      "Model saved in file: models/model_n1620.ckpt\n",
      "step 163, training accuracy 0.58\n",
      "Model saved in file: models/model_n1630.ckpt\n",
      "step 164, training accuracy 0.6\n",
      "Model saved in file: models/model_n1640.ckpt\n",
      "step 165, training accuracy 0.66\n",
      "Model saved in file: models/model_n1650.ckpt\n",
      "step 166, training accuracy 0.58\n",
      "Model saved in file: models/model_n1660.ckpt\n",
      "step 167, training accuracy 0.66\n",
      "Model saved in file: models/model_n1670.ckpt\n",
      "step 168, training accuracy 0.56\n",
      "Model saved in file: models/model_n1680.ckpt\n",
      "step 169, training accuracy 0.6\n",
      "Model saved in file: models/model_n1690.ckpt\n",
      "step 170, training accuracy 0.58\n",
      "Model saved in file: models/model_n1700.ckpt\n",
      "step 171, training accuracy 0.62\n",
      "Model saved in file: models/model_n1710.ckpt\n",
      "step 172, training accuracy 0.48\n",
      "Model saved in file: models/model_n1720.ckpt\n",
      "step 173, training accuracy 0.62\n",
      "Model saved in file: models/model_n1730.ckpt\n",
      "step 174, training accuracy 0.66\n",
      "Model saved in file: models/model_n1740.ckpt\n",
      "step 175, training accuracy 0.7\n",
      "Model saved in file: models/model_n1750.ckpt\n",
      "step 176, training accuracy 0.58\n",
      "Model saved in file: models/model_n1760.ckpt\n",
      "step 177, training accuracy 0.54\n",
      "Model saved in file: models/model_n1770.ckpt\n",
      "step 178, training accuracy 0.52\n",
      "Model saved in file: models/model_n1780.ckpt\n",
      "step 179, training accuracy 0.48\n",
      "Model saved in file: models/model_n1790.ckpt\n",
      "step 180, training accuracy 0.52\n",
      "Model saved in file: models/model_n1800.ckpt\n",
      "step 181, training accuracy 0.58\n",
      "Model saved in file: models/model_n1810.ckpt\n",
      "step 182, training accuracy 0.5\n",
      "Model saved in file: models/model_n1820.ckpt\n",
      "step 183, training accuracy 0.6\n",
      "Model saved in file: models/model_n1830.ckpt\n",
      "step 184, training accuracy 0.52\n",
      "Model saved in file: models/model_n1840.ckpt\n",
      "step 185, training accuracy 0.68\n",
      "Model saved in file: models/model_n1850.ckpt\n",
      "step 186, training accuracy 0.48\n",
      "Model saved in file: models/model_n1860.ckpt\n",
      "step 187, training accuracy 0.66\n",
      "Model saved in file: models/model_n1870.ckpt\n",
      "step 188, training accuracy 0.36\n",
      "Model saved in file: models/model_n1880.ckpt\n",
      "step 189, training accuracy 0.54\n",
      "Model saved in file: models/model_n1890.ckpt\n",
      "step 190, training accuracy 0.54\n",
      "Model saved in file: models/model_n1900.ckpt\n",
      "step 191, training accuracy 0.6\n",
      "Model saved in file: models/model_n1910.ckpt\n",
      "step 192, training accuracy 0.58\n",
      "Model saved in file: models/model_n1920.ckpt\n",
      "step 193, training accuracy 0.68\n",
      "Model saved in file: models/model_n1930.ckpt\n",
      "step 194, training accuracy 0.64\n",
      "Model saved in file: models/model_n1940.ckpt\n",
      "step 195, training accuracy 0.52\n",
      "Model saved in file: models/model_n1950.ckpt\n",
      "step 196, training accuracy 0.54\n",
      "Model saved in file: models/model_n1960.ckpt\n",
      "step 197, training accuracy 0.62\n",
      "Model saved in file: models/model_n1970.ckpt\n",
      "step 198, training accuracy 0.58\n",
      "Model saved in file: models/model_n1980.ckpt\n",
      "step 199, training accuracy 0.54\n",
      "Model saved in file: models/model_n1990.ckpt\n",
      "step 200, training accuracy 0.64\n",
      "Model saved in file: models/model_n2000.ckpt\n",
      "step 201, training accuracy 0.66\n",
      "Model saved in file: models/model_n2010.ckpt\n",
      "step 202, training accuracy 0.56\n",
      "Model saved in file: models/model_n2020.ckpt\n",
      "step 203, training accuracy 0.62\n",
      "Model saved in file: models/model_n2030.ckpt\n",
      "step 204, training accuracy 0.58\n",
      "Model saved in file: models/model_n2040.ckpt\n",
      "step 205, training accuracy 0.54\n",
      "Model saved in file: models/model_n2050.ckpt\n",
      "step 206, training accuracy 0.64\n",
      "Model saved in file: models/model_n2060.ckpt\n",
      "step 207, training accuracy 0.56\n",
      "Model saved in file: models/model_n2070.ckpt\n",
      "step 208, training accuracy 0.48\n",
      "Model saved in file: models/model_n2080.ckpt\n",
      "step 209, training accuracy 0.48\n",
      "Model saved in file: models/model_n2090.ckpt\n",
      "step 210, training accuracy 0.62\n",
      "Model saved in file: models/model_n2100.ckpt\n",
      "step 211, training accuracy 0.48\n",
      "Model saved in file: models/model_n2110.ckpt\n",
      "step 212, training accuracy 0.48\n",
      "Model saved in file: models/model_n2120.ckpt\n",
      "step 213, training accuracy 0.42\n",
      "Model saved in file: models/model_n2130.ckpt\n",
      "step 214, training accuracy 0.6\n",
      "Model saved in file: models/model_n2140.ckpt\n",
      "step 215, training accuracy 0.48\n",
      "Model saved in file: models/model_n2150.ckpt\n",
      "step 216, training accuracy 0.68\n",
      "Model saved in file: models/model_n2160.ckpt\n",
      "step 217, training accuracy 0.66\n",
      "Model saved in file: models/model_n2170.ckpt\n",
      "step 218, training accuracy 0.62\n",
      "Model saved in file: models/model_n2180.ckpt\n",
      "step 219, training accuracy 0.54\n",
      "Model saved in file: models/model_n2190.ckpt\n",
      "step 220, training accuracy 0.44\n",
      "Model saved in file: models/model_n2200.ckpt\n",
      "step 221, training accuracy 0.68\n",
      "Model saved in file: models/model_n2210.ckpt\n",
      "step 222, training accuracy 0.64\n",
      "Model saved in file: models/model_n2220.ckpt\n",
      "step 223, training accuracy 0.52\n",
      "Model saved in file: models/model_n2230.ckpt\n",
      "step 224, training accuracy 0.54\n",
      "Model saved in file: models/model_n2240.ckpt\n",
      "step 225, training accuracy 0.5\n",
      "Model saved in file: models/model_n2250.ckpt\n",
      "step 226, training accuracy 0.44\n",
      "Model saved in file: models/model_n2260.ckpt\n",
      "step 227, training accuracy 0.58\n",
      "Model saved in file: models/model_n2270.ckpt\n",
      "step 228, training accuracy 0.52\n",
      "Model saved in file: models/model_n2280.ckpt\n",
      "step 229, training accuracy 0.52\n",
      "Model saved in file: models/model_n2290.ckpt\n",
      "step 230, training accuracy 0.66\n",
      "Model saved in file: models/model_n2300.ckpt\n",
      "step 231, training accuracy 0.56\n",
      "Model saved in file: models/model_n2310.ckpt\n",
      "step 232, training accuracy 0.6\n",
      "Model saved in file: models/model_n2320.ckpt\n",
      "step 233, training accuracy 0.54\n",
      "Model saved in file: models/model_n2330.ckpt\n",
      "step 234, training accuracy 0.58\n",
      "Model saved in file: models/model_n2340.ckpt\n",
      "step 235, training accuracy 0.66\n",
      "Model saved in file: models/model_n2350.ckpt\n",
      "step 236, training accuracy 0.62\n",
      "Model saved in file: models/model_n2360.ckpt\n",
      "step 237, training accuracy 0.56\n",
      "Model saved in file: models/model_n2370.ckpt\n",
      "step 238, training accuracy 0.6\n",
      "Model saved in file: models/model_n2380.ckpt\n",
      "step 239, training accuracy 0.5\n",
      "Model saved in file: models/model_n2390.ckpt\n",
      "step 240, training accuracy 0.5\n",
      "Model saved in file: models/model_n2400.ckpt\n",
      "step 241, training accuracy 0.46\n",
      "Model saved in file: models/model_n2410.ckpt\n",
      "step 242, training accuracy 0.5\n",
      "Model saved in file: models/model_n2420.ckpt\n",
      "step 243, training accuracy 0.7\n",
      "Model saved in file: models/model_n2430.ckpt\n",
      "step 244, training accuracy 0.54\n",
      "Model saved in file: models/model_n2440.ckpt\n",
      "step 245, training accuracy 0.56\n",
      "Model saved in file: models/model_n2450.ckpt\n",
      "step 246, training accuracy 0.5\n",
      "Model saved in file: models/model_n2460.ckpt\n",
      "step 247, training accuracy 0.56\n",
      "Model saved in file: models/model_n2470.ckpt\n",
      "step 248, training accuracy 0.58\n",
      "Model saved in file: models/model_n2480.ckpt\n",
      "step 249, training accuracy 0.72\n",
      "Model saved in file: models/model_n2490.ckpt\n",
      "step 250, training accuracy 0.48\n",
      "Model saved in file: models/model_n2500.ckpt\n",
      "step 251, training accuracy 0.68\n",
      "Model saved in file: models/model_n2510.ckpt\n",
      "step 252, training accuracy 0.68\n",
      "Model saved in file: models/model_n2520.ckpt\n",
      "step 253, training accuracy 0.6\n",
      "Model saved in file: models/model_n2530.ckpt\n",
      "step 254, training accuracy 0.44\n",
      "Model saved in file: models/model_n2540.ckpt\n",
      "step 255, training accuracy 0.64\n",
      "Model saved in file: models/model_n2550.ckpt\n",
      "step 256, training accuracy 0.62\n",
      "Model saved in file: models/model_n2560.ckpt\n",
      "step 257, training accuracy 0.8\n",
      "Model saved in file: models/model_n2570.ckpt\n",
      "step 258, training accuracy 0.66\n",
      "Model saved in file: models/model_n2580.ckpt\n",
      "step 259, training accuracy 0.66\n",
      "Model saved in file: models/model_n2590.ckpt\n",
      "step 260, training accuracy 0.6\n",
      "Model saved in file: models/model_n2600.ckpt\n",
      "step 261, training accuracy 0.56\n",
      "Model saved in file: models/model_n2610.ckpt\n",
      "step 262, training accuracy 0.62\n",
      "Model saved in file: models/model_n2620.ckpt\n",
      "step 263, training accuracy 0.64\n",
      "Model saved in file: models/model_n2630.ckpt\n",
      "step 264, training accuracy 0.7\n",
      "Model saved in file: models/model_n2640.ckpt\n",
      "step 265, training accuracy 0.64\n",
      "Model saved in file: models/model_n2650.ckpt\n",
      "step 266, training accuracy 0.62\n",
      "Model saved in file: models/model_n2660.ckpt\n",
      "step 267, training accuracy 0.5\n",
      "Model saved in file: models/model_n2670.ckpt\n",
      "step 268, training accuracy 0.6\n",
      "Model saved in file: models/model_n2680.ckpt\n",
      "step 269, training accuracy 0.68\n",
      "Model saved in file: models/model_n2690.ckpt\n",
      "step 270, training accuracy 0.6\n",
      "Model saved in file: models/model_n2700.ckpt\n",
      "step 271, training accuracy 0.46\n",
      "Model saved in file: models/model_n2710.ckpt\n",
      "step 272, training accuracy 0.58\n",
      "Model saved in file: models/model_n2720.ckpt\n",
      "step 273, training accuracy 0.56\n",
      "Model saved in file: models/model_n2730.ckpt\n",
      "step 274, training accuracy 0.62\n",
      "Model saved in file: models/model_n2740.ckpt\n",
      "step 275, training accuracy 0.54\n",
      "Model saved in file: models/model_n2750.ckpt\n",
      "step 276, training accuracy 0.44\n",
      "Model saved in file: models/model_n2760.ckpt\n",
      "step 277, training accuracy 0.52\n",
      "Model saved in file: models/model_n2770.ckpt\n",
      "step 278, training accuracy 0.64\n",
      "Model saved in file: models/model_n2780.ckpt\n",
      "step 279, training accuracy 0.48\n",
      "Model saved in file: models/model_n2790.ckpt\n",
      "step 280, training accuracy 0.52\n",
      "Model saved in file: models/model_n2800.ckpt\n",
      "step 281, training accuracy 0.52\n",
      "Model saved in file: models/model_n2810.ckpt\n",
      "step 282, training accuracy 0.44\n",
      "Model saved in file: models/model_n2820.ckpt\n",
      "step 283, training accuracy 0.54\n",
      "Model saved in file: models/model_n2830.ckpt\n",
      "step 284, training accuracy 0.58\n",
      "Model saved in file: models/model_n2840.ckpt\n",
      "step 285, training accuracy 0.56\n",
      "Model saved in file: models/model_n2850.ckpt\n",
      "step 286, training accuracy 0.44\n",
      "Model saved in file: models/model_n2860.ckpt\n",
      "step 287, training accuracy 0.56\n",
      "Model saved in file: models/model_n2870.ckpt\n",
      "step 288, training accuracy 0.62\n",
      "Model saved in file: models/model_n2880.ckpt\n",
      "step 289, training accuracy 0.6\n",
      "Model saved in file: models/model_n2890.ckpt\n",
      "step 290, training accuracy 0.4\n",
      "Model saved in file: models/model_n2900.ckpt\n",
      "step 291, training accuracy 0.74\n",
      "Model saved in file: models/model_n2910.ckpt\n",
      "step 292, training accuracy 0.6\n",
      "Model saved in file: models/model_n2920.ckpt\n",
      "step 293, training accuracy 0.54\n",
      "Model saved in file: models/model_n2930.ckpt\n",
      "step 294, training accuracy 0.52\n",
      "Model saved in file: models/model_n2940.ckpt\n",
      "step 295, training accuracy 0.5\n",
      "Model saved in file: models/model_n2950.ckpt\n",
      "step 296, training accuracy 0.72\n",
      "Model saved in file: models/model_n2960.ckpt\n",
      "step 297, training accuracy 0.52\n",
      "Model saved in file: models/model_n2970.ckpt\n",
      "step 298, training accuracy 0.54\n",
      "Model saved in file: models/model_n2980.ckpt\n",
      "step 299, training accuracy 0.62\n",
      "Model saved in file: models/model_n2990.ckpt\n",
      "step 300, training accuracy 0.6\n",
      "Model saved in file: models/model_n3000.ckpt\n",
      "step 301, training accuracy 0.58\n",
      "Model saved in file: models/model_n3010.ckpt\n",
      "step 302, training accuracy 0.64\n",
      "Model saved in file: models/model_n3020.ckpt\n",
      "step 303, training accuracy 0.54\n",
      "Model saved in file: models/model_n3030.ckpt\n",
      "step 304, training accuracy 0.58\n",
      "Model saved in file: models/model_n3040.ckpt\n",
      "step 305, training accuracy 0.66\n",
      "Model saved in file: models/model_n3050.ckpt\n",
      "step 306, training accuracy 0.54\n",
      "Model saved in file: models/model_n3060.ckpt\n",
      "step 307, training accuracy 0.58\n",
      "Model saved in file: models/model_n3070.ckpt\n",
      "step 308, training accuracy 0.58\n",
      "Model saved in file: models/model_n3080.ckpt\n",
      "step 309, training accuracy 0.56\n",
      "Model saved in file: models/model_n3090.ckpt\n",
      "step 310, training accuracy 0.54\n",
      "Model saved in file: models/model_n3100.ckpt\n",
      "step 311, training accuracy 0.62\n",
      "Model saved in file: models/model_n3110.ckpt\n",
      "step 312, training accuracy 0.62\n",
      "Model saved in file: models/model_n3120.ckpt\n",
      "step 313, training accuracy 0.5\n",
      "Model saved in file: models/model_n3130.ckpt\n",
      "step 314, training accuracy 0.62\n",
      "Model saved in file: models/model_n3140.ckpt\n",
      "step 315, training accuracy 0.58\n",
      "Model saved in file: models/model_n3150.ckpt\n",
      "step 316, training accuracy 0.46\n",
      "Model saved in file: models/model_n3160.ckpt\n",
      "step 317, training accuracy 0.62\n",
      "Model saved in file: models/model_n3170.ckpt\n",
      "step 318, training accuracy 0.5\n",
      "Model saved in file: models/model_n3180.ckpt\n",
      "step 319, training accuracy 0.48\n",
      "Model saved in file: models/model_n3190.ckpt\n",
      "step 320, training accuracy 0.6\n",
      "Model saved in file: models/model_n3200.ckpt\n",
      "step 321, training accuracy 0.52\n",
      "Model saved in file: models/model_n3210.ckpt\n",
      "step 322, training accuracy 0.46\n",
      "Model saved in file: models/model_n3220.ckpt\n",
      "step 323, training accuracy 0.5\n",
      "Model saved in file: models/model_n3230.ckpt\n",
      "step 324, training accuracy 0.48\n",
      "Model saved in file: models/model_n3240.ckpt\n",
      "step 325, training accuracy 0.48\n",
      "Model saved in file: models/model_n3250.ckpt\n",
      "step 326, training accuracy 0.6\n",
      "Model saved in file: models/model_n3260.ckpt\n",
      "step 327, training accuracy 0.58\n",
      "Model saved in file: models/model_n3270.ckpt\n",
      "step 328, training accuracy 0.6\n",
      "Model saved in file: models/model_n3280.ckpt\n",
      "step 329, training accuracy 0.64\n",
      "Model saved in file: models/model_n3290.ckpt\n",
      "step 330, training accuracy 0.36\n",
      "Model saved in file: models/model_n3300.ckpt\n",
      "step 331, training accuracy 0.58\n",
      "Model saved in file: models/model_n3310.ckpt\n",
      "step 332, training accuracy 0.56\n",
      "Model saved in file: models/model_n3320.ckpt\n",
      "step 333, training accuracy 0.58\n",
      "Model saved in file: models/model_n3330.ckpt\n",
      "step 334, training accuracy 0.54\n",
      "Model saved in file: models/model_n3340.ckpt\n",
      "step 335, training accuracy 0.58\n",
      "Model saved in file: models/model_n3350.ckpt\n",
      "step 336, training accuracy 0.62\n",
      "Model saved in file: models/model_n3360.ckpt\n",
      "step 337, training accuracy 0.5\n",
      "Model saved in file: models/model_n3370.ckpt\n",
      "step 338, training accuracy 0.66\n",
      "Model saved in file: models/model_n3380.ckpt\n",
      "step 339, training accuracy 0.56\n",
      "Model saved in file: models/model_n3390.ckpt\n",
      "step 340, training accuracy 0.62\n",
      "Model saved in file: models/model_n3400.ckpt\n",
      "step 341, training accuracy 0.56\n",
      "Model saved in file: models/model_n3410.ckpt\n",
      "step 342, training accuracy 0.54\n",
      "Model saved in file: models/model_n3420.ckpt\n",
      "step 343, training accuracy 0.62\n",
      "Model saved in file: models/model_n3430.ckpt\n",
      "step 344, training accuracy 0.68\n",
      "Model saved in file: models/model_n3440.ckpt\n",
      "step 345, training accuracy 0.52\n",
      "Model saved in file: models/model_n3450.ckpt\n",
      "step 346, training accuracy 0.68\n",
      "Model saved in file: models/model_n3460.ckpt\n",
      "step 347, training accuracy 0.66\n",
      "Model saved in file: models/model_n3470.ckpt\n",
      "step 348, training accuracy 0.6\n",
      "Model saved in file: models/model_n3480.ckpt\n",
      "step 349, training accuracy 0.68\n",
      "Model saved in file: models/model_n3490.ckpt\n",
      "step 350, training accuracy 0.54\n",
      "Model saved in file: models/model_n3500.ckpt\n",
      "step 351, training accuracy 0.54\n",
      "Model saved in file: models/model_n3510.ckpt\n",
      "step 352, training accuracy 0.64\n",
      "Model saved in file: models/model_n3520.ckpt\n",
      "step 353, training accuracy 0.62\n",
      "Model saved in file: models/model_n3530.ckpt\n",
      "step 354, training accuracy 0.54\n",
      "Model saved in file: models/model_n3540.ckpt\n",
      "step 355, training accuracy 0.56\n",
      "Model saved in file: models/model_n3550.ckpt\n",
      "step 356, training accuracy 0.54\n",
      "Model saved in file: models/model_n3560.ckpt\n",
      "step 357, training accuracy 0.58\n",
      "Model saved in file: models/model_n3570.ckpt\n",
      "step 358, training accuracy 0.64\n",
      "Model saved in file: models/model_n3580.ckpt\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[59710,1,60,300]\n\t [[Node: pool1_1/AvgPool = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 1, 2, 1], padding=\"SAME\", strides=[1, 1, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_1/Relu)]]\n\nCaused by op 'pool1_1/AvgPool', defined at:\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-98c02889022f>\", line 3, in <module>\n    yConv,keep_prob = deepnn(x)\n  File \"<ipython-input-27-b0ab007f4ddc>\", line 13, in deepnn\n    hPool1 = meanPool(hConv1)\n  File \"<ipython-input-19-d5a9db09372a>\", line 16, in meanPool\n    strides=[1, 1, 2, 1], padding='SAME')\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 1930, in avg_pool\n    name=name)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 68, in _avg_pool\n    data_format=data_format, name=name)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[59710,1,60,300]\n\t [[Node: pool1_1/AvgPool = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 1, 2, 1], padding=\"SAME\", strides=[1, 1, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_1/Relu)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[59710,1,60,300]\n\t [[Node: pool1_1/AvgPool = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 1, 2, 1], padding=\"SAME\", strides=[1, 1, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_1/Relu)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-62a7a15b9167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0myCur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         print('test accuracy %g step %d' % (accuracy.eval(feed_dict={\n\u001b[0;32m---> 23\u001b[0;31m             x: xTest, y_: yTest,keep_prob: 1.0}), i/(batchsize*10)))         \n\u001b[0m",
      "\u001b[0;32m/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \"\"\"\n\u001b[0;32m--> 570\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_dup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4453\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4454\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4455\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[59710,1,60,300]\n\t [[Node: pool1_1/AvgPool = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 1, 2, 1], padding=\"SAME\", strides=[1, 1, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_1/Relu)]]\n\nCaused by op 'pool1_1/AvgPool', defined at:\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-98c02889022f>\", line 3, in <module>\n    yConv,keep_prob = deepnn(x)\n  File \"<ipython-input-27-b0ab007f4ddc>\", line 13, in deepnn\n    hPool1 = meanPool(hConv1)\n  File \"<ipython-input-19-d5a9db09372a>\", line 16, in meanPool\n    strides=[1, 1, 2, 1], padding='SAME')\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 1930, in avg_pool\n    name=name)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 68, in _avg_pool\n    data_format=data_format, name=name)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/s2c/anaconda3/envs/AlgoTrading/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[59710,1,60,300]\n\t [[Node: pool1_1/AvgPool = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 1, 2, 1], padding=\"SAME\", strides=[1, 1, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_1/Relu)]]\n"
     ]
    }
   ],
   "source": [
    "batchSize = 50\n",
    "restore = 0\n",
    "with tf.Session() as sess:\n",
    "    if restore == 1:\n",
    "        saver.restore(sess,\"models/model_340.ckpt\")\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    for i in range(0,len(xTrain),batchSize):\n",
    "        xCur = xTrain[i:i+batchSize,:]\n",
    "        yCur = yTrain[i:i+batchSize]\n",
    "        if i % (batchSize*10) == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: xCur, y_: yCur, keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i/(batchSize*10), train_accuracy))\n",
    "            save_path = saver.save(sess, \"models/model_n%d.ckpt\" % (i/batchSize))\n",
    "            print(\"Model saved in file: %s\" % save_path)                      \n",
    "        train_step.run(feed_dict={x: xCur, y_: yCur, keep_prob: .5})\n",
    "\n",
    "    for i in range(0,len(xTest),batchSize):\n",
    "        xCur = xTest[i:i+batchSize,:]\n",
    "        yCur = yTest[i:i+batchSize]\n",
    "        print('test accuracy %g step %d' % (accuracy.eval(feed_dict={\n",
    "            x: xTest, y_: yTest,keep_prob: 1.0}), i/(batchsize*10)))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "range(len(xTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xTrain[0:30,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yTest == [[0, 1 ,0 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([295784, 295784])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yTrain == [[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "29933 + 149196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([420751, 420751])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yTrain == [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716535"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "295784 +  420751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41279770004256594"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "295784/716535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.587202299957434"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "420751/716535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4224941173288617"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.587202299957434/0.41279770004256594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:AlgoTrading]",
   "language": "python",
   "name": "conda-env-AlgoTrading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
